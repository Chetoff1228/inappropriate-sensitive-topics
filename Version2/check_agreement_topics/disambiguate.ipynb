{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбираемся какой семпл из какой группы"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Всего три группы\n",
    "1) толока\n",
    "    4 шага подавались разные группы потенциальных тем\n",
    "2) самостоятельная разметка\n",
    "3) ключевые слова\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Делаем словарь чтобы мапить предложения на тип сбора "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT2SOURCEDICT = {}\n",
    "TEXT_processed2SOURCEDICT = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_len(text):\n",
    "    if len(text.split()) > 5 and len (text)< 250:\n",
    "        return True\n",
    "    return None\n",
    "def is_mostly_russian(text):\n",
    "    text = str(text)\n",
    "    russian_letters_count = len(re.findall(\"[а-яА-Я]\",text))\n",
    "    eng_letters_count = len(re.findall(\"[a-zA-Z]\",text))\n",
    "    if russian_letters_count > eng_letters_count:\n",
    "        return True\n",
    "    return None\n",
    "def depersonalize(text):\n",
    "    text = str(text)\n",
    "    url_regex = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\"\n",
    "    text= re.sub(url_regex, \"url\", text)\n",
    "    text = re.sub(\"id[\\d]*\",'',text)\n",
    "    text = re.sub(\"> ?\",'',text)\n",
    "    text = re.sub(\"@[\\w]*\",'',text)\n",
    "#     text = re.sub(\"\\+[\\d]*\", \"\", text)\n",
    "    text = re.sub(\"[\\d]+\", \"NUMBER\", text)\n",
    "    text = re.sub(\">>\", \"\", text)\n",
    "#     text = re.sub(\"[\\d]{3,100}\", \"\", text)\n",
    "    text = re.sub(\"[\\t|\\n|\\r]\", \"\", text)\n",
    "    text = re.sub(\"[(OP)|url|nickname|phone_number]\", \"\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toloka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_toloka_list = []\n",
    "folder = './gr1_toloka/'\n",
    "for f in os.listdir(folder):\n",
    "    if 'onerow' in f:\n",
    "        filepath = os.path.join(folder, f)\n",
    "        df_curr = pd.read_csv(filepath)\n",
    "        df_toloka_list.append(df_curr)\n",
    "df_toloka = pd.concat(df_toloka_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_toloka_verify = pd.read_csv(\"./gr1_toloka/parts1to4_merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9946"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_toloka_verify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9946"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_toloka)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df_toloka['text']) - set(df_toloka_verify['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in set(df_toloka['text'].tolist()):\n",
    "    TEXT2SOURCEDICT[t] = 'toloka'\n",
    "    t_proc = depersonalize(t)\n",
    "    TEXT_processed2SOURCEDICT[t_proc] = 'toloka'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_self_list = []\n",
    "folder = './gr2_self/'\n",
    "for f in os.listdir(folder):\n",
    "    \n",
    "    filepath = os.path.join(folder, f)\n",
    "    df_curr = pd.read_csv(filepath)\n",
    "    df_self_list.append(df_curr)\n",
    "df_self = pd.concat(df_self_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28371"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df_self['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in set(df_self['text'].tolist()):\n",
    "#     if t in TEXT2SOURCEDICT:\n",
    "#         TEXT2SOURCEDICT[t] = TEXT2SOURCEDICT[t]  + '_self'\n",
    "#         t_proc = depersonalize(t)\n",
    "#         TEXT2SOURCEDICT[t_proc] = TEXT2SOURCEDICT[t_proc]  + '_self'\n",
    "#     else:\n",
    "#         TEXT2SOURCEDICT[t] = 'self'\n",
    "#         t_proc = depersonalize(t)\n",
    "#         TEXT2SOURCEDICT[t_proc] = 'self'\n",
    "        \n",
    "    TEXT2SOURCEDICT[t] = 'self'\n",
    "    t_proc = depersonalize(t)\n",
    "    TEXT_processed2SOURCEDICT[t_proc] = 'self'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kw_list = []\n",
    "folder = './gr3_kw_self/'\n",
    "for f in os.listdir(folder):\n",
    "    if '_kw.csv' in f:\n",
    "        filepath = os.path.join(folder, f)\n",
    "        df_curr = pd.read_csv(filepath)\n",
    "        df_kw_list.append(df_curr)\n",
    "        \n",
    "df_kw = pd.concat(df_kw_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in set(df_kw['processed'].tolist()):\n",
    "#     if t in TEXT2SOURCEDICT and TEXT2SOURCEDICT[t] != 'kw':\n",
    "#         TEXT2SOURCEDICT[t] = TEXT2SOURCEDICT[t] + '_kw'\n",
    "#         t_proc = depersonalize(t)\n",
    "#         TEXT2SOURCEDICT[t_proc] = TEXT2SOURCEDICT[t_proc] + '_kw'\n",
    "#     else:\n",
    "#         TEXT2SOURCEDICT[t] = 'kw'\n",
    "#         t_proc = depersonalize(t)\n",
    "#         TEXT2SOURCEDICT[t_proc] = 'kw'\n",
    "      \n",
    "#     if t not in TEXT2SOURCEDICT:\n",
    "    TEXT2SOURCEDICT[t] = 'kw'\n",
    "    t_proc = depersonalize(t)\n",
    "    TEXT_processed2SOURCEDICT[t_proc] = 'kw'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From forums no KW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_nokw_list = []\n",
    "# folder = './gr3_kw_self/'\n",
    "# for f in os.listdir(folder):\n",
    "#     if '_nokw.csv' in f:\n",
    "#         filepath = os.path.join(folder, f)\n",
    "#         df_curr = pd.read_csv(filepath)\n",
    "#         df_nokw_list.append(df_curr)\n",
    "        \n",
    "# df_nokw = pd.concat(df_nokw_list)\n",
    "\n",
    "# from tqdm import tqdm\n",
    "# all_outof_kw = set(df_nokw['processed'].tolist())\n",
    "\n",
    "# for t in tqdm(all_outof_kw, total = len(all_outof_kw)):\n",
    "#     if t in TEXT2SOURCEDICT:\n",
    "#         TEXT2SOURCEDICT[t] = TEXT2SOURCEDICT[t] + '_nokw'\n",
    "#         t_proc = depersonalize(t)\n",
    "#         TEXT2SOURCEDICT[t_proc] = TEXT2SOURCEDICT[t_proc] + '_nokw'\n",
    "#     else:\n",
    "#         TEXT2SOURCEDICT[t] = 'nokw'\n",
    "#         t_proc = depersonalize(t)\n",
    "#         TEXT2SOURCEDICT[t_proc] = 'nokw'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Olga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kwolga_list = []\n",
    "folder = './gr3_kw_olga/'\n",
    "for f in os.listdir(folder):\n",
    "    filepath = os.path.join(folder, f)\n",
    "    df_curr = pd.read_csv(filepath, header = None)\n",
    "    df_kwolga_list.append(df_curr)\n",
    "    \n",
    "df_kwolga = pd.concat(df_kwolga_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Не вижу повода спорить, есть девушки которые х...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Замените слово жирный на алкоголик и никто уже...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>В большинстве случаев жирные куски говна оправ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Хочу высказать своё мнение, которое никому не ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>у меня акне первой степени, и у меня 1000 и 1 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  Не вижу повода спорить, есть девушки которые х...\n",
       "1  Замените слово жирный на алкоголик и никто уже...\n",
       "2  В большинстве случаев жирные куски говна оправ...\n",
       "3  Хочу высказать своё мнение, которое никому не ...\n",
       "4  у меня акне первой степени, и у меня 1000 и 1 ..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kwolga.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12351"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_kwolga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in set(df_kwolga[0].tolist()):\n",
    "#     if t in TEXT2SOURCEDICT:\n",
    "#         TEXT2SOURCEDICT[t] = TEXT2SOURCEDICT[t] + '_kwolga'\n",
    "#         t_proc = depersonalize(t)\n",
    "#         TEXT2SOURCEDICT[t_proc] = TEXT2SOURCEDICT[t_proc] + '_kwolga'\n",
    "#     else:\n",
    "#         TEXT2SOURCEDICT[t] = 'kwolga'\n",
    "#         t_proc = depersonalize(t)\n",
    "#         TEXT2SOURCEDICT[t_proc] = 'kwolga'\n",
    "#     if t not in  TEXT2SOURCEDICT:\n",
    "    TEXT2SOURCEDICT[t] = 'kwolga'\n",
    "    t_proc = depersonalize(t)\n",
    "    TEXT_processed2SOURCEDICT[t_proc] = 'kwolga'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41726"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TEXT2SOURCEDICT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Применяем к выложенному датасету"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sensitive_published = pd.read_csv(\"crowd_vs_part1234self.csv\")\n",
    "df_sensitive_published = pd.read_csv(\"../sensitive_topics/sensitive_topics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>offline_crime</th>\n",
       "      <th>online_crime</th>\n",
       "      <th>drugs</th>\n",
       "      <th>gambling</th>\n",
       "      <th>pornography</th>\n",
       "      <th>prostitution</th>\n",
       "      <th>slavery</th>\n",
       "      <th>suicide</th>\n",
       "      <th>terrorism</th>\n",
       "      <th>weapons</th>\n",
       "      <th>body_shaming</th>\n",
       "      <th>health_shaming</th>\n",
       "      <th>politics</th>\n",
       "      <th>racism</th>\n",
       "      <th>religion</th>\n",
       "      <th>sexual_minorities</th>\n",
       "      <th>sexism</th>\n",
       "      <th>social_injustice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>РРРРРРЯЯЯЯЯЯЯ РУССКИЕ ВАНЬКИ НИКОМУ НЕ НУЖНЫ!!...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>По моему, быдло тот кто осуждает чужие предпоч...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  offline_crime  \\\n",
       "0  РРРРРРЯЯЯЯЯЯЯ РУССКИЕ ВАНЬКИ НИКОМУ НЕ НУЖНЫ!!...            0.0   \n",
       "1  По моему, быдло тот кто осуждает чужие предпоч...            0.0   \n",
       "\n",
       "   online_crime  drugs  gambling  pornography  prostitution  slavery  suicide  \\\n",
       "0           0.0    0.0       0.0          0.0           0.0      0.0      0.0   \n",
       "1           0.0    0.0       0.0          1.0           0.8      0.0      0.0   \n",
       "\n",
       "   terrorism  weapons  body_shaming  health_shaming  politics  racism  \\\n",
       "0        0.0      0.0           0.0             0.0       0.0     1.0   \n",
       "1        0.0      0.0           0.0             0.0       0.0     0.0   \n",
       "\n",
       "   religion  sexual_minorities  sexism  social_injustice  \n",
       "0       0.0                0.0     1.0               0.0  \n",
       "1       0.0                0.0     1.0               0.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sensitive_published.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33303"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df_sensitive_published['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 364 marked as tolooka but actually not found\n"
     ]
    }
   ],
   "source": [
    "source_list = []\n",
    "not_found = 0\n",
    "for t in df_sensitive_published['text'].tolist():\n",
    "    t_proc = depersonalize(t)\n",
    "    if t in TEXT2SOURCEDICT:\n",
    "        source_list.append(TEXT2SOURCEDICT[t])\n",
    "    elif t_proc in TEXT_processed2SOURCEDICT:\n",
    "        source_list.append(TEXT_processed2SOURCEDICT[t_proc])\n",
    "    else:\n",
    "        not_found += 1\n",
    "        source_list.append('toloka')\n",
    "print(\" {} marked as tolooka but actually not found\".format(not_found))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sensitive_published['source'] = source_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sensitive_published.to_csv(\"sensitive_topics_vs_source.csv\", index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33303"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(source_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('toloka', 9654), ('self', 9232), ('kwolga', 7702), ('kw', 6715)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(source_list).most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>offline_crime</th>\n",
       "      <th>online_crime</th>\n",
       "      <th>drugs</th>\n",
       "      <th>gambling</th>\n",
       "      <th>pornography</th>\n",
       "      <th>prostitution</th>\n",
       "      <th>slavery</th>\n",
       "      <th>suicide</th>\n",
       "      <th>terrorism</th>\n",
       "      <th>weapons</th>\n",
       "      <th>body_shaming</th>\n",
       "      <th>health_shaming</th>\n",
       "      <th>politics</th>\n",
       "      <th>racism</th>\n",
       "      <th>religion</th>\n",
       "      <th>sexual_minorities</th>\n",
       "      <th>sexism</th>\n",
       "      <th>social_injustice</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>РРРРРРЯЯЯЯЯЯЯ РУССКИЕ ВАНЬКИ НИКОМУ НЕ НУЖНЫ!!...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>toloka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>По моему, быдло тот кто осуждает чужие предпоч...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>toloka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Бабы это вообще безхуйные сиськастые ссущие си...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>toloka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>изнасиловалиа говорила что девственницаЯ так д...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>toloka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>и что ? не сосут только уебищные тни, видосов ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>toloka</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  offline_crime  \\\n",
       "0  РРРРРРЯЯЯЯЯЯЯ РУССКИЕ ВАНЬКИ НИКОМУ НЕ НУЖНЫ!!...            0.0   \n",
       "1  По моему, быдло тот кто осуждает чужие предпоч...            0.0   \n",
       "2  Бабы это вообще безхуйные сиськастые ссущие си...            0.0   \n",
       "3  изнасиловалиа говорила что девственницаЯ так д...            0.0   \n",
       "4  и что ? не сосут только уебищные тни, видосов ...            0.0   \n",
       "\n",
       "   online_crime  drugs  gambling  pornography  prostitution  slavery  suicide  \\\n",
       "0           0.0    0.0       0.0          0.0          0.00      0.0      0.0   \n",
       "1           0.0    0.0       0.0          1.0          0.80      0.0      0.0   \n",
       "2           0.0    0.0       0.0          0.0          0.00      0.0      0.0   \n",
       "3           0.0    0.0       0.0          1.0          0.00      0.0      0.0   \n",
       "4           0.0    0.0       0.0          1.0          0.75      0.0      0.0   \n",
       "\n",
       "   terrorism  weapons  body_shaming  health_shaming  politics  racism  \\\n",
       "0        0.0      0.0           0.0             0.0       0.0     1.0   \n",
       "1        0.0      0.0           0.0             0.0       0.0     0.0   \n",
       "2        0.0      0.0           0.0             0.0       0.0     0.0   \n",
       "3        0.0      0.0           0.0             0.0       0.0     0.0   \n",
       "4        0.0      0.0           0.0             0.0       0.0     0.0   \n",
       "\n",
       "   religion  sexual_minorities  sexism  social_injustice  source  \n",
       "0       0.0                0.0     1.0               0.0  toloka  \n",
       "1       0.0                0.0     1.0               0.0  toloka  \n",
       "2       0.0                0.0     1.0               0.0  toloka  \n",
       "3       0.0                0.0     1.0               0.0  toloka  \n",
       "4       0.0                0.0     1.0               0.0  toloka  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sensitive_published[df_sensitive_published['source']=='toloka'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_TEXTS_SET = set(df_sensitive_published['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ищем not_found в толоке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfound_toloka_texts = []\n",
    "unfound_toloka_texts_proc = []\n",
    "\n",
    "found = []\n",
    "for text,source in TEXT2SOURCEDICT.items():\n",
    "    if source == 'toloka':\n",
    "        t_proc = depersonalize(text)\n",
    "        if text in ALL_TEXTS_SET or t_proc in ALL_TEXTS_SET:\n",
    "            found.append(text)\n",
    "        else:\n",
    "            unfound_toloka_texts.append(text)\n",
    "            unfound_toloka_texts_proc.append(t_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9300, 619)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(found)), len(set(unfound_toloka_texts_proc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ищем not_found в self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfound_self_texts = []\n",
    "unfound_self_texts_proc = []\n",
    "cnt = 0\n",
    "found = []\n",
    "for t,source in TEXT2SOURCEDICT.items():\n",
    "    if source == 'self':\n",
    "        cnt  += 1\n",
    "        t_proc = depersonalize(t)\n",
    "        if t in ALL_TEXTS_SET or t_proc in ALL_TEXTS_SET:\n",
    "            found.append(text)\n",
    "        else:\n",
    "            unfound_self_texts.append(t)\n",
    "            unfound_self_texts_proc.append(t_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unfound_self_texts_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "toloka_unfound = list(set(unfound_toloka_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toloka_unfound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
