{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Callable, Iterable, Optional, Sequence, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics import masi_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "from krippendorff.krippendorff import _coincidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "РАСХОЖДЕНИЕ ИЗ -ЗА РАЗНЫХ МЕТРИК ДИСТАНЦИИ И СООТВЕТСКНЕО ПЛОЗО КОГДА МНОГО ИЗМЕРЕНИЙ СТАНОВИТСЯ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_coincidences() missing 1 required positional argument: 'value_domain'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-310-acc35253348a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[0mvalue_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[0malpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-310-acc35253348a>\u001b[0m in \u001b[0;36malpha\u001b[1;34m(reliability_data, value_counts, value_domain, dtype)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mdistance_metric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmasi_distance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_coincidences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m     \u001b[0mn_v\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0me\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_random_coincidences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: _coincidences() missing 1 required positional argument: 'value_domain'"
     ]
    }
   ],
   "source": [
    "def alpha(reliability_data: Optional[Iterable[Any]] = None, value_counts: Optional[np.ndarray] = None,\n",
    "          value_domain: Optional[Sequence[Any]] = None,\n",
    "           dtype: Any = np.float64) -> float:\n",
    "\n",
    "    if (reliability_data is None) == (value_counts is None):\n",
    "        raise ValueError(\"Either reliability_data or value_counts must be provided, but not both.\")\n",
    "\n",
    "    # Don't know if it's a list or numpy array. If it's the latter, the truth value is ambiguous. So, ask for None.\n",
    "    if value_counts is None:\n",
    "        reliability_data = np.asarray(reliability_data)\n",
    "\n",
    "        if value_domain is None:\n",
    "            value_domain = np.unique(reliability_data[~np.isnan(reliability_data)])\n",
    "        else:\n",
    "            value_domain = np.asarray(value_domain)\n",
    "            assert np.isin(reliability_data, np.append(value_domain, np.nan)).all(), \\\n",
    "                \"The reliability data contains out-of-domain values.\"\n",
    "\n",
    "        value_counts = _reliability_data_to_value_counts(reliability_data, value_domain)\n",
    "    else:  # elif reliability_data is None\n",
    "        value_counts = np.asarray(value_counts)\n",
    "\n",
    "        if value_domain is None:\n",
    "            value_domain = np.arange(value_counts.shape[1])\n",
    "        else:\n",
    "            value_domain = np.asarray(value_domain)\n",
    "            assert value_counts.shape[1] == len(value_domain), \\\n",
    "                \"The value domain should be equal to the number of columns of value_counts.\"\n",
    "\n",
    "    assert len(value_domain) > 1, \"There has to be more than one value in the domain.\"\n",
    "\n",
    "    distance_metric = masi_distance\n",
    "\n",
    "    o = _coincidences(value_counts, dtype=dtype)\n",
    "    n_v = o.sum(axis=0)\n",
    "    e = _random_coincidences(n_v, dtype=dtype)\n",
    "    d = _distances(value_domain, distance_metric, n_v, dtype=dtype)\n",
    "    return 1 - (o * d).sum() / (e * d).sum()\n",
    "\n",
    "value_counts = np.array([[1, 0, 0, 0],[0, 0, 0, 0]])\n",
    "alpha(value_counts=value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4444444444444444"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stats.stackexchange.com/questions/407453/krippendorffs-alpha-in-r-for-multi-label-annotation\n",
    "import nltk\n",
    "from nltk.metrics import agreement\n",
    "from nltk.metrics.agreement import AnnotationTask\n",
    "\n",
    "\n",
    "task_data = [('coder1','Item0',frozenset(['l1','l2'])),\n",
    "('coder2','Item0',frozenset(['l1'])),\n",
    "('coder1','Item1',frozenset(['l1','l2'])),\n",
    "('coder2','Item1',frozenset(['l1','l2'])),\n",
    "('coder1','Item2',frozenset(['l1'])),\n",
    "('coder2','Item2',frozenset(['l1']))]\n",
    "\n",
    "task = AnnotationTask(distance = masi_distance)\n",
    "\n",
    "task.load_array(task_data)\n",
    "\n",
    "task.alpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calc_agreement_within_group(df_group):\n",
    "    worker2id = {}\n",
    "    for pair in df_group['ASSIGNMENT:worker_id'].tolist():\n",
    "        if pair not in worker2id:\n",
    "            worker2id[pair] = len(worker2id)\n",
    "    df_group['worker_idx'] = df_group['ASSIGNMENT:worker_id'].map(worker2id)\n",
    "    \n",
    "    text2ids = {}\n",
    "    for t in set(df_group['INPUT:text'].tolist()):\n",
    "        if t not in text2ids:\n",
    "            text2ids[t] = len(text2ids)\n",
    "    df_group['text_idx'] = df_group['INPUT:text'].map(text2ids)\n",
    "    ids2text = {idx:text for text,idx in text2ids.items()}\n",
    "    \n",
    "    reply_columns = [c for c in df_group.columns if 'OUTPUT' in c]\n",
    "    \n",
    "    collected_data = []\n",
    "    for i,el in df_group.iterrows():\n",
    "        coder_idx = el['worker_idx']\n",
    "        \n",
    "        item_idx = el['text_idx']\n",
    "        labels_list = []\n",
    "        for repl in reply_columns:\n",
    "#             print(repl[7:], el[repl])\n",
    "            if el[repl] == True:\n",
    "                labels_list.append(repl[7:])\n",
    "        \n",
    "        if len(labels_list) == 0: labels_list = ['none']\n",
    "#         print(labels_list)\n",
    "        collected_triplet = (coder_idx,item_idx,frozenset(labels_list))\n",
    "        collected_data.append(collected_triplet)\n",
    "        \n",
    "#         collected_texts.append(el['INPUT:text'])\n",
    "        \n",
    "#         break\n",
    "    task = AnnotationTask(distance = masi_distance)\n",
    "    \n",
    "#     print(\"collected_data\", collected_data[:10])\n",
    "\n",
    "    task.load_array(collected_data)\n",
    "\n",
    "    return task.alpha()\n",
    "\n",
    "\n",
    "def get_agreement_batch(batch_name, drop_traintest_examples = False, print_output = False,):\n",
    "    if batch_name == 'first': \n",
    "        raw_files = ['g1r.tsv','g2r.tsv','g3r.tsv']\n",
    "    elif batch_name == 'fourth':\n",
    "        raw_files = ['g1_4r.tsv','g2_4r.tsv','g3_4r.tsv']\n",
    "    elif batch_name == 'old':\n",
    "        raw_files = ['maybe_old/g1r.tsv','maybe_old/g2r.tsv']\n",
    "    \n",
    "    index2textset_notrest = {}\n",
    "    index2textset_withtrtest = {}\n",
    "    for file in raw_files:\n",
    "       \n",
    "        batch_path = \"./directly_from_toloka/\"+file\n",
    "        df_curr= pd.read_csv(batch_path, sep = '\\t')\n",
    "        \n",
    "        index2textset_withtrtest[file] = set(df_curr['INPUT:text'])\n",
    "        \n",
    "        if drop_traintest_examples == True:\n",
    "            golden_column = [c for c in df_curr.columns if 'GOLDEN' in c]\n",
    "            df_curr = df_curr[df_curr[golden_column[1]].isna()]\n",
    "        \n",
    "        index2textset_notrest[file] = set(df_curr['INPUT:text'])\n",
    "    \n",
    "    intersect_text_no_tr_test = index2textset_notrest[file]\n",
    "    engaged_text_withtrtest = index2textset_withtrtest[file]\n",
    "    for f in index2textset_notrest:\n",
    "        intersect_text_no_tr_test = intersect_text_no_tr_test.intersection(index2textset_notrest[f])\n",
    "        engaged_text_withtrtest = engaged_text_withtrtest.union(index2textset_withtrtest[f])\n",
    "        \n",
    "    if print_output == True: print(\"intersecting texts are {} \\n\".format(len(intersect_text)))\n",
    "    \n",
    "    collected_agreements = []\n",
    "    for i, file in enumerate(raw_files):\n",
    "        batch_path = \"./directly_from_toloka/\"+file\n",
    "        df_curr_common= pd.read_csv(batch_path, sep = '\\t')\n",
    "        \n",
    "        if drop_traintest_examples == True:\n",
    "            golden_column = [c for c in df_curr_common.columns if 'GOLDEN' in c]\n",
    "            df_curr_common = df_curr_common[df_curr_common[golden_column[1]].isna()]\n",
    "        \n",
    "        columns_to_merge = [c for c in df_curr_common.columns if c == 'INPUT:text' or 'OUTPUT' in c  or c =='ASSIGNMENT:worker_id']\n",
    "        df_curr_common = df_curr_common[columns_to_merge]\n",
    "        \n",
    "        current_aggr = calc_agreement_within_group(df_curr_common)\n",
    "#         print(\"current_aggr\", current_aggr)\n",
    "        collected_agreements.append(current_aggr)\n",
    "        \n",
    "#         break\n",
    "    if print_output == True: \n",
    "        print(\"\\n\")\n",
    "        print(\"collected_agreements\", collected_agreements)\n",
    "        print(\"average agreements\", np.mean(collected_agreements))\n",
    "    return intersect_text_no_tr_test, engaged_text_withtrtest, collected_agreements#intersect_text_no_tr_test - с тренй-тест если выбрать опцию не дропать тртест\n",
    "\n",
    "    \n",
    "int_text, eng_text, afrr = get_agreement_batch_no_intersect('first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.10661798648012055, 0.6364950196276913, 0.3874856997131322]"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first batch agreement list - [0.10661798648012055, 0.6364950196276913, 0.3874856997131322]\n",
      "fourth batch agreement list - [0.4455289036288479, 0.5516957933012958, 0.6099929668782522]\n",
      "old batch agreement list - [0.41087633393756817, 0.43702795130017413]\n"
     ]
    }
   ],
   "source": [
    "def get_whole_agreement_and_intersections(drop_traintest_examples):\n",
    "    intersected_texts_from_batches = set()\n",
    "    all_unique_texts_from_batches =  set()\n",
    "    toloka_agreements_list = []\n",
    "    for batch in ['first','fourth','old']:#\n",
    "        intersect_texts, all_unique_texts_set, aggr_list = get_agreement_batch(batch, drop_traintest_examples = drop_traintest_examples)\n",
    "        intersected_texts_from_batches = intersected_texts_from_batches.union(intersect_texts)\n",
    "        all_unique_texts_from_batches = all_unique_texts_from_batches.union(all_unique_texts_set)\n",
    "        print(\"{} batch agreement list - {}\".format(batch, aggr_list))\n",
    "        toloka_agreements_list.extend(aggr_list)\n",
    "    return intersected_texts_from_batches,all_unique_texts_from_batches, np.mean(toloka_agreements_list)\n",
    "common_texts_whole_toloka_notrtes, all_engaged_texts, whole_toloka_agreement = get_whole_agreement_and_intersections(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [0.10661798648012055, 0.6364950196276913, 0.3874856997131322] - без трейн-тест семплов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6732, 10130, 0.44821508185838527)"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(common_texts_whole_toloka_notrtes), len(all_engaged_texts), whole_toloka_agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first batch agreement list - [0.7004942315456364, 0.6767382024830249, 0.5799682486670625]\n",
      "fourth batch agreement list - [0.5321843310977421, 0.5966316162108932, 0.6597914632811841]\n",
      "old batch agreement list - [0.4142966632292012, 0.4489685586640344]\n"
     ]
    }
   ],
   "source": [
    "common_texts_whole_toloka_withtrtest,  all_engaged_texts, whole_toloka_agreement = get_whole_agreement_and_intersections(drop_traintest_examples = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6798, 10130, 0.5761341643973473)"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(common_texts_whole_toloka_withtrtest), len(all_engaged_texts), whole_toloka_agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6798, 10130, 0.5761341643973473)"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(common_texts_whole_toloka_withtrtest), len(all_engaged_texts), whole_toloka_agreement"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Не очень понятно какому расчету больше доверять - с учетом трейн-тест семплов или нет. Наличие чрезмерного количества ответов на трейн-тест семплы мождет перекручивать значение. Необходимо проверить насколько часто в реально выложенных от толоки семпах встречались семплы из тренировочных сетов. Сделаем это в след секции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проверяем пересечение текстов фактических батчей с сырой толоки с текстами заявленными в спарсенном датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_len(text):\n",
    "    if len(text.split()) > 5 and len (text)< 250:\n",
    "        return True\n",
    "    return None\n",
    "def is_mostly_russian(text):\n",
    "    text = str(text)\n",
    "    russian_letters_count = len(re.findall(\"[а-яА-Я]\",text))\n",
    "    eng_letters_count = len(re.findall(\"[a-zA-Z]\",text))\n",
    "    if russian_letters_count > eng_letters_count:\n",
    "        return True\n",
    "    return None\n",
    "def depersonalize(text):\n",
    "    text = str(text)\n",
    "    url_regex = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\"\n",
    "    text= re.sub(url_regex, \"url\", text)\n",
    "    text = re.sub(\"id[\\d]*\",'',text)\n",
    "    text = re.sub(\"> ?\",'',text)\n",
    "    text = re.sub(\"@[\\w]*\",'',text)\n",
    "#     text = re.sub(\"\\+[\\d]*\", \"\", text)\n",
    "    text = re.sub(\"[\\d]+\", \"NUMBER\", text)\n",
    "    text = re.sub(\">>\", \"\", text)\n",
    "#     text = re.sub(\"[\\d]{3,100}\", \"\", text)\n",
    "    text = re.sub(\"[\\t|\\n|\\r]\", \"\", text)\n",
    "    text = re.sub(\"[(OP)|url|nickname|phone_number]\", \"\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sensitive = pd.read_csv(\"sensitive_topics_vs_source.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sensitive_toloka = df_sensitive[df_sensitive['source'] == 'toloka']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9654"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_sensitive_toloka)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9654"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sensitive_toloka_texts_set = set(df_sensitive_toloka['text'])\n",
    "len(df_sensitive_toloka_texts_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### если дропать трейн тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first batch agreement list - [0.10661798648012055, 0.6364950196276913, 0.3874856997131322]\n",
      "fourth batch agreement list - [0.4455289036288479, 0.5516957933012958, 0.6099929668782522]\n",
      "old batch agreement list - [0.41087633393756817, 0.43702795130017413]\n"
     ]
    }
   ],
   "source": [
    "common_texts_whole_toloka_notrtes, all_engaged_texts, whole_toloka_agreement = get_whole_agreement_and_intersections(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_texts_whole_toloka_prep = set([depersonalize(t) for t in common_texts_whole_toloka_notrtes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6061"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_sensitive_toloka_texts_set & common_texts_whole_toloka_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6278226641806505"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_sensitive_toloka_texts_set & common_texts_whole_toloka_prep)/len(df_sensitive_toloka_texts_set)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "если использовать тексты только общие внутри каждого батча с учетом дропа трейн-тест то покрытие толоки довольно низкое"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### если НЕ дропать трейн тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first batch agreement list - [0.7004942315456364, 0.6767382024830249, 0.5799682486670625]\n",
      "fourth batch agreement list - [0.5321843310977421, 0.5966316162108932, 0.6597914632811841]\n",
      "old batch agreement list - [0.4142966632292012, 0.4489685586640344]\n"
     ]
    }
   ],
   "source": [
    "common_texts_whole_toloka_withtrtest,  all_engaged_texts, whole_toloka_agreement = get_whole_agreement_and_intersections(drop_traintest_examples = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_texts_whole_toloka_withtrtest_prep = set([depersonalize(t) for t in common_texts_whole_toloka_withtrtest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6112"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_sensitive_toloka_texts_set & common_texts_whole_toloka_withtrtest_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6331054485187487"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_sensitive_toloka_texts_set & common_texts_whole_toloka_withtrtest_prep)/len(df_sensitive_toloka_texts_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.6331054485187487"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "если использовать тексты только общие внутри каждого батча БЕЗ дропа трейн-тест то покрытие толоки тоже довольно низкое"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_engaged_texts_prep = set([depersonalize(t) for t in all_engaged_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8854"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_sensitive_toloka_texts_set & all_engaged_texts_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9171327946964989"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_sensitive_toloka_texts_set & all_engaged_texts_prep)/len(df_sensitive_toloka_texts_set)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Получается что в оснвоном все то что используется в итоговом датасете как толока включает в себя не только пересекающиеся семплы внутри батчей, но и еще такие семплы, которые по каким-то причинам 9скоре всего просто ошибочно) не вошли в ту или иную группу внутри какого-то бачта. Это не оч хорошо, так как такого рода семплы не размечены на предмет топкиа внутри одной группы но не размечены на предмет топика внутри другой. Однако учитывая тот факт, что семплы как правило предварительно каким-либо образом подбирались, можно остаивть все как есть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пытаемся попрунить толокерский датасет для увеличения согласованности"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Думаю, что с учетом выясненной существенной применяемости тренй-тест семплов в итоговом датасете следует не ибавляться от них, но те голоса, которые явно делают поблажку собранным данным (там где сотни голосов  примененных к одному семплу) - срезать количество этих голосов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import krippendorff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_agreement_within_group(df_group):\n",
    "    worker2id = {}\n",
    "    for pair in df_group['ASSIGNMENT:worker_id'].tolist():\n",
    "        if pair not in worker2id:\n",
    "            worker2id[pair] = len(worker2id)\n",
    "    df_group['worker_idx'] = df_group['ASSIGNMENT:worker_id'].map(worker2id)\n",
    "    \n",
    "    text2ids = {}\n",
    "    for t in set(df_group['INPUT:text'].tolist()):\n",
    "        if t not in text2ids:\n",
    "            text2ids[t] = len(text2ids)\n",
    "    df_group['text_idx'] = df_group['INPUT:text'].map(text2ids)\n",
    "    ids2text = {idx:text for text,idx in text2ids.items()}\n",
    "    \n",
    "    reply_columns = [c for c in df_group.columns if 'OUTPUT' in c]\n",
    "    \n",
    "    collected_data = []\n",
    "    for i,el in df_group.iterrows():\n",
    "        coder_idx = el['worker_idx']\n",
    "        \n",
    "        item_idx = el['text_idx']\n",
    "        labels_list = []\n",
    "        for repl in reply_columns:\n",
    "            if el[repl] == True:\n",
    "                labels_list.append(repl[7:])\n",
    "        \n",
    "        if len(labels_list) == 0: labels_list = ['none']\n",
    "#         print(labels_list)\n",
    "        collected_triplet = (coder_idx,item_idx,frozenset(labels_list))\n",
    "        collected_data.append(collected_triplet)\n",
    "        \n",
    "        \n",
    "#         break\n",
    "    task = AnnotationTask(distance = masi_distance)\n",
    "    \n",
    "#     print(\"collected_data\", collected_data[:10])\n",
    "\n",
    "    task.load_array(collected_data)\n",
    "\n",
    "    return task.alpha(), collected_data, [r[7:] for r in reply_columns], ids2text\n",
    "\n",
    "\n",
    "def meets_strict_req(element_list,admit_multi, min_votes):\n",
    "    admitable_multichoice_count = admit_multi\n",
    "    multichoice_list = [el for el in element_list if el > min_votes] \n",
    "    if len(multichoice_list) <= admitable_multichoice_count:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def krippendorf_with_filtering(collected_data,columns,ids2text, admit_multi, min_votes):\n",
    "    count_dict = {i:{c:0 for c in columns} for i in range(len(ids2text))}\n",
    "\n",
    "    for _ ,item_idx,label_set in collected_data:\n",
    "        for label in label_set:\n",
    "            count_dict[item_idx][label] += 1\n",
    "            \n",
    "    value_counts_real = []\n",
    "    value_counts_pruned = []\n",
    "    value_counts_pruned_data = []\n",
    "    \n",
    "    value_counts_strict = []\n",
    "    value_counts_strict_data = []\n",
    "    \n",
    "    for task_idx in range(len(ids2text)):\n",
    "        current_count_element_real = [0] * len(columns) \n",
    "        current_count_element_pruned = [0] * len(columns)\n",
    "        for idx, lbl in enumerate(columns):\n",
    "            if count_dict[task_idx][lbl] > 20:\n",
    "                current_count_element_pruned[idx] = 20\n",
    "                value_counts_pruned_data.append(ids2text[task_idx])\n",
    "            else:\n",
    "                current_count_element_pruned[idx] = count_dict[task_idx][lbl]\n",
    "                value_counts_pruned_data.append(ids2text[task_idx])\n",
    "                \n",
    "            current_count_element_real[idx] = count_dict[task_idx][lbl]\n",
    "           \n",
    "        value_counts_real.append(current_count_element_real)\n",
    "        value_counts_pruned.append(current_count_element_pruned)\n",
    "        \n",
    "        is_strict = meets_strict_req(current_count_element_pruned,admit_multi, min_votes)\n",
    "        if is_strict == True:\n",
    "            value_counts_strict.append(current_count_element_pruned)\n",
    "            value_counts_strict_data.append(ids2text[task_idx])\n",
    "     \n",
    "    aplha_no_strict_real  = krippendorff.alpha(value_counts=np.array(value_counts_real),level_of_measurement='nominal')\n",
    "    aplha_no_strict_pruned = krippendorff.alpha(value_counts=np.array(value_counts_pruned),level_of_measurement='nominal')\n",
    "    alpha_strict = krippendorff.alpha(value_counts=np.array(value_counts_strict),level_of_measurement='nominal')\n",
    "    \n",
    "    unique_texts_from_all_val_counts = set(value_counts_pruned_data)\n",
    "    unique_texts_from_strict_val_counts = set(value_counts_strict_data)\n",
    "    \n",
    "    return (aplha_no_strict_real,aplha_no_strict_pruned, alpha_strict), unique_texts_from_all_val_counts, unique_texts_from_strict_val_counts\n",
    "        \n",
    "\n",
    "def get_aggr_batch_with_filtering(batch_name, admit_multi, min_votes, drop_traintest_examples = False, print_output = False):\n",
    "    if batch_name == 'first': \n",
    "        raw_files = ['g1r.tsv','g2r.tsv','g3r.tsv']\n",
    "    elif batch_name == 'fourth':\n",
    "        raw_files = ['g1_4r.tsv','g2_4r.tsv','g3_4r.tsv']\n",
    "    elif batch_name == 'old':\n",
    "        raw_files = ['maybe_old/g1r.tsv','maybe_old/g2r.tsv']\n",
    "    \n",
    "    engaged_text_withtrtest= set()\n",
    "    intersect_text_no_tr_test = None       \n",
    "        \n",
    "    if print_output == True: print(\"intersecting texts are {} \\n\".format(len(intersect_text)))\n",
    "    \n",
    "    collected_agreements = []\n",
    "    collected_agreements_strict = []\n",
    "    \n",
    "    val_cnts_strict_set = set()\n",
    "    val_cnts_NOstrict_set = set()\n",
    "    \n",
    "    for i, file in enumerate(raw_files):\n",
    "        batch_path = \"./directly_from_toloka/\"+file\n",
    "        df_curr_common= pd.read_csv(batch_path, sep = '\\t')\n",
    "        \n",
    "        engaged_text_withtrtest = engaged_text_withtrtest.union(set(df_curr_common['INPUT:text']))\n",
    "        \n",
    "        if drop_traintest_examples == True:\n",
    "            golden_column = [c for c in df_curr_common.columns if 'GOLDEN' in c]\n",
    "            df_curr_common = df_curr_common[df_curr_common[golden_column[1]].isna()]\n",
    "            \n",
    "        if intersect_text_no_tr_test:\n",
    "            intersect_text_no_tr_test = intersect_text_no_tr_test.intersection(set(df_curr_common['INPUT:text']))\n",
    "        else:\n",
    "            intersect_text_no_tr_test = set(df_curr_common['INPUT:text'])\n",
    "        \n",
    "        columns_to_merge = [c for c in df_curr_common.columns if c == 'INPUT:text' or 'OUTPUT' in c  or c =='ASSIGNMENT:worker_id']\n",
    "        df_curr_common = df_curr_common[columns_to_merge]\n",
    "        \n",
    "        alpha_curr, collected_data_curr, reply_columns_curr, ids2text = calc_agreement_within_group(df_curr_common)\n",
    "        aplhas_c, value_counts_no_strict, value_counts_strict = krippendorf_with_filtering(collected_data_curr, reply_columns_curr, ids2text,admit_multi, min_votes)\n",
    "        aplha_no_strict_real_c ,aplha_no_strict_pruned_c , alpha_strict_c = aplhas_c\n",
    "                \n",
    "#         assert abs(alpha_curr - aplha_no_strict_real_c) < 0.021, \"from nltk {} from kripp {} in {}\".format(round(alpha_curr,3),round(aplha_no_strict_real_c,3), batch_path)\n",
    "        \n",
    "        if print_output == True:\n",
    "            if abs(alpha_curr - aplha_no_strict_real_c) > 0.021:\n",
    "                print(\"from nltk {} from kripp {} in {}\".format(round(alpha_curr,3),round(aplha_no_strict_real_c,3), batch_path))\n",
    "        \n",
    "        collected_agreements.append(aplha_no_strict_pruned_c)\n",
    "        collected_agreements_strict.append(alpha_strict_c)\n",
    "    \n",
    "        \n",
    "        val_cnts_strict_set = val_cnts_strict_set.union(value_counts_strict)\n",
    "        val_cnts_NOstrict_set = val_cnts_NOstrict_set.union(value_counts_no_strict)  \n",
    "        \n",
    "        \n",
    "    assert len(val_cnts_NOstrict_set) == len(engaged_text_withtrtest), \"val_cnts_NOstrict_set {}, engaged_text_withtrtest {}\".format(len(val_cnts_NOstrict_set),len(engaged_text_withtrtest))\n",
    "        \n",
    "    return collected_agreements, collected_agreements_strict, val_cnts_NOstrict_set, val_cnts_strict_set\n",
    "\n",
    "afrr,aggr_s, initial_texts_count, strict_filtered_counts_t  = get_aggr_batch_with_filtering('first',admit_multi=2,min_votes=3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filter_stats_from_all_batches(admit_multi,min_votes):\n",
    "    collected_agreements = []\n",
    "    initial_texts_set = set ()\n",
    "    strict_texts_set = set() \n",
    "    for batch in ['first','fourth']:#'old'\n",
    "        agreement_list_c, agreement_list_strict_c, initial_texts_set_c, strict_filtered_txt_set_c  = get_aggr_batch_with_filtering(batch,\n",
    "                                                                                                              admit_multi=admit_multi,\n",
    "                                                                                                              min_votes=min_votes)\n",
    "        collected_agreements.extend(agreement_list_c)\n",
    "        initial_texts_set = initial_texts_set.union(initial_texts_set_c)\n",
    "        strict_texts_set = strict_texts_set.union(strict_filtered_txt_set_c)\n",
    "        \n",
    "#     print(collected_agreements)\n",
    "#     print(len(initial_texts_set),len(strict_texts_set))\n",
    "    \n",
    "    return np.mean(collected_agreements), len(initial_texts_set), np.mean(agreement_list_strict_c),len(strict_texts_set)\n",
    "    \n",
    "aggr_init, text_init, aggr_strict, texts_strict = get_filter_stats_from_all_batches(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4973849218904598, 7009, 0.4987658241591957, 7000)"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggr_init, text_init, aggr_strict, texts_strict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!!ПОНЯТЬ ПОЧЕМУ ПО РАЩНОМУ СЧИТАЕТСЯ КРИПЕНДОРФА ПРИ БОЛЬШЕМ КОЛ-ВЕ РАЗМЕРНОСТЕЙ В СТАРЫХ БАТЧАХ МБ НАДО ВВЕСТИ МЕТРИКУ КАК В НЛТК!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_different_filtering_options():\n",
    "    collected_data = []\n",
    "    for admit_multi_curr in [2,3,4,5]:#\n",
    "        for min_votes_curr in [2,3,4,5,6,7]:#\n",
    "            aggr_init, text_init, aggr_strict, texts_strict = get_filter_stats_from_all_batches(admit_multi_curr,min_votes_curr)\n",
    "            collected_data.append([admit_multi_curr,min_votes_curr, aggr_init, text_init, aggr_strict, texts_strict])\n",
    "    df_report = pd.DataFrame(data = collected_data, columns = ['admit_multi','min_votes','init_aggr','init_txt_num','strict_aggr', 'strict_txt_num']) \n",
    "    return df_report\n",
    "\n",
    "df_r = check_different_filtering_options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r.head(100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
