{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "# import eli5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "df_val = pd.read_csv(\"val.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_val(val):\n",
    "    return round(val)\n",
    "label_name = 'inappropriate'\n",
    "threshold = 0\n",
    "df = df[(df[label_name] >= 1-threshold)|(df[label_name] <=threshold)]\n",
    "df_val = df_val[(df_val[label_name] >= 1-threshold)|(df_val[label_name] <=threshold)]\n",
    "df_test = df_test[(df_test[label_name] >= 1-threshold) | (df_test[label_name] <=threshold)]\n",
    "\n",
    "df[label_name] = df[label_name].apply(round_val)\n",
    "df_val[label_name] = df_val[label_name].apply(round_val)\n",
    "df_test[label_name] = df_test[label_name].apply(round_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-idf logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/kashnitsky/logistic-regression-tf-idf-baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val = pd.concat([df, df_val])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        я думал что левиафаны - это те медленные страх...\n",
       "2        Напоминаю, что пора искать актис невзрослого п...\n",
       "3        курю лет пятнадцать никаких проблем кроме како...\n",
       "4        окей, я тогда проведу парад гетеросексуалов, п...\n",
       "5        Напоминаю ватникам, что в США общий налог всег...\n",
       "                               ...                        \n",
       "16327    Законно ли в РФ обменивать валюту на соответст...\n",
       "16328    Алкоголь это петля которая затягивается с кажд...\n",
       "16330    Ну вот эту \"икону\" я бы посмотрел.Фотография Р...\n",
       "16331    И как избавился? Я не могу сам себя заставить ...\n",
       "16332               Нет) Оба вторые - рестайл и дорестайл)\n",
       "Name: text, Length: 95507, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No stopwords removal, no preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_tfidf(sw = None, ngram_range=(1, 3), max_features=150000, text_label = 'text'):\n",
    "    \n",
    "    print(\"ngram_range {}, max_features {}\".format(ngram_range, max_features))\n",
    "    \n",
    "    text_transformer = TfidfVectorizer(stop_words=sw, ngram_range=ngram_range, lowercase=True, max_features=max_features)\n",
    "    X_train_text = text_transformer.fit_transform(train_val[text_label].tolist())\n",
    "    \n",
    "#     print(X_train_text)\n",
    "#     raise Exception(\"STOPE\")\n",
    "    \n",
    "    X_test_text = text_transformer.transform(df_test[text_label])\n",
    "\n",
    "    logit = LogisticRegression(C=5e1, solver='lbfgs', multi_class='multinomial', random_state=17, n_jobs=4)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=17)\n",
    "\n",
    "    cv_results = cross_val_score(logit, X_train_text, train_val['inappropriate'], cv=skf, scoring='f1_micro')\n",
    "\n",
    "    print(cv_results, cv_results.mean())\n",
    "    \n",
    "    logit.fit(X_train_text, train_val['inappropriate'])\n",
    "    test_preds = logit.predict(X_test_text)\n",
    "    print(classification_report(df_test['inappropriate'], test_preds))\n",
    "\n",
    "\n",
    "    \n",
    "# check_tfidf()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ngram_range (1, 2), max_features 100000\n",
    "[0.79504764 0.79776987 0.79592691 0.80027224 0.79639809] 0.7970829504475575\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.84      0.89      0.87      7839\n",
    "           1       0.63      0.52      0.57      2726\n",
    "\n",
    "    accuracy                           0.80     10565\n",
    "   macro avg       0.74      0.71      0.72     10565\n",
    "weighted avg       0.79      0.80      0.79     10565\n",
    "\n",
    "====================================================================================================\n",
    "ngram_range (1, 2), max_features 150000\n",
    "[0.79939273 0.801225   0.80247107 0.80194754 0.79943458] 0.8008941875531506\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.84      0.90      0.87      7839\n",
    "           1       0.64      0.51      0.57      2726\n",
    "\n",
    "    accuracy                           0.80     10565\n",
    "   macro avg       0.74      0.71      0.72     10565\n",
    "weighted avg       0.79      0.80      0.79     10565\n",
    "\n",
    "====================================================================================================\n",
    "ngram_range (1, 2), max_features 300000\n",
    "[0.80164381 0.80201026 0.80608345 0.80346579 0.80252343] 0.8031453467978886\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.84      0.90      0.87      7839\n",
    "           1       0.65      0.52      0.58      2726\n",
    "\n",
    "    accuracy                           0.80     10565\n",
    "   macro avg       0.75      0.71      0.72     10565\n",
    "weighted avg       0.79      0.80      0.80     10565\n",
    "\n",
    "ngram_range (1, 3), max_features 100000\n",
    "[0.79269186 0.79174956 0.79576985 0.79461808 0.79566515] 0.794098901194495\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.84      0.89      0.86      7839\n",
    "           1       0.62      0.52      0.56      2726\n",
    "\n",
    "    accuracy                           0.79     10565\n",
    "   macro avg       0.73      0.70      0.71     10565\n",
    "weighted avg       0.78      0.79      0.79     10565\n",
    "\n",
    "====================================================================================================\n",
    "ngram_range (1, 3), max_features 150000\n",
    "[0.79515234 0.7960423  0.79959164 0.79932988 0.79582221] 0.7971876739999025\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.84      0.89      0.87      7839\n",
    "           1       0.63      0.52      0.57      2726\n",
    "\n",
    "    accuracy                           0.80     10565\n",
    "   macro avg       0.73      0.70      0.72     10565\n",
    "weighted avg       0.79      0.80      0.79     10565\n",
    "\n",
    "====================================================================================================\n",
    "ngram_range (1, 3), max_features 300000\n",
    "[0.79975919 0.80106795 0.80676404 0.80383226 0.79980106] 0.8022448999828435\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.84      0.90      0.87      7839\n",
    "           1       0.64      0.51      0.57      2726\n",
    "\n",
    "    accuracy                           0.80     10565\n",
    "   macro avg       0.74      0.71      0.72     10565\n",
    "weighted avg       0.79      0.80      0.79     10565\n",
    "\n",
    "====================================================================================================\n",
    "ngram_range (1, 4), max_features 100000\n",
    "[0.79284892 0.79677521 0.79540338 0.79692163 0.79241925] 0.7948736754711991\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.84      0.90      0.87      7839\n",
    "           1       0.63      0.50      0.56      2726\n",
    "\n",
    "    accuracy                           0.80     10565\n",
    "   macro avg       0.74      0.70      0.71     10565\n",
    "weighted avg       0.78      0.80      0.79     10565\n",
    "\n",
    "====================================================================================================\n",
    "ngram_range (1, 4), max_features 150000\n",
    "[0.79761282 0.79824102 0.79932988 0.800534   0.80016753] 0.7991770498524968\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.84      0.89      0.87      7839\n",
    "           1       0.62      0.52      0.57      2726\n",
    "\n",
    "    accuracy                           0.80     10565\n",
    "   macro avg       0.73      0.71      0.72     10565\n",
    "weighted avg       0.79      0.80      0.79     10565\n",
    "\n",
    "====================================================================================================\n",
    "ngram_range (1, 4), max_features 300000\n",
    "[0.7965658  0.80023034 0.80226166 0.80372755 0.79959164] 0.800475401328234\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.84      0.90      0.87      7839\n",
    "           1       0.64      0.52      0.57      2726\n",
    "\n",
    "    accuracy                           0.80     10565\n",
    "   macro avg       0.74      0.71      0.72     10565\n",
    "weighted avg       0.79      0.80      0.79     10565\n",
    "\n",
    "===================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngram_range (1, 3), max_features 100000\n",
      "[0.79269186 0.79174956 0.79576985 0.79461808 0.79566515] 0.794098901194495\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.86      7839\n",
      "           1       0.62      0.52      0.56      2726\n",
      "\n",
      "    accuracy                           0.79     10565\n",
      "   macro avg       0.73      0.70      0.71     10565\n",
      "weighted avg       0.78      0.79      0.79     10565\n",
      "\n",
      "====================================================================================================\n",
      "ngram_range (1, 3), max_features 150000\n",
      "[0.79515234 0.7960423  0.79959164 0.79932988 0.79582221] 0.7971876739999025\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.87      7839\n",
      "           1       0.63      0.52      0.57      2726\n",
      "\n",
      "    accuracy                           0.80     10565\n",
      "   macro avg       0.73      0.70      0.72     10565\n",
      "weighted avg       0.79      0.80      0.79     10565\n",
      "\n",
      "====================================================================================================\n",
      "ngram_range (1, 3), max_features 300000\n",
      "[0.79975919 0.80106795 0.80676404 0.80383226 0.79980106] 0.8022448999828435\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87      7839\n",
      "           1       0.64      0.51      0.57      2726\n",
      "\n",
      "    accuracy                           0.80     10565\n",
      "   macro avg       0.74      0.71      0.72     10565\n",
      "weighted avg       0.79      0.80      0.79     10565\n",
      "\n",
      "====================================================================================================\n",
      "ngram_range (1, 4), max_features 100000\n",
      "[0.79284892 0.79677521 0.79540338 0.79692163 0.79241925] 0.7948736754711991\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87      7839\n",
      "           1       0.63      0.50      0.56      2726\n",
      "\n",
      "    accuracy                           0.80     10565\n",
      "   macro avg       0.74      0.70      0.71     10565\n",
      "weighted avg       0.78      0.80      0.79     10565\n",
      "\n",
      "====================================================================================================\n",
      "ngram_range (1, 4), max_features 150000\n",
      "[0.79761282 0.79824102 0.79932988 0.800534   0.80016753] 0.7991770498524968\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.87      7839\n",
      "           1       0.62      0.52      0.57      2726\n",
      "\n",
      "    accuracy                           0.80     10565\n",
      "   macro avg       0.73      0.71      0.72     10565\n",
      "weighted avg       0.79      0.80      0.79     10565\n",
      "\n",
      "====================================================================================================\n",
      "ngram_range (1, 4), max_features 300000\n",
      "[0.7965658  0.80023034 0.80226166 0.80372755 0.79959164] 0.800475401328234\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87      7839\n",
      "           1       0.64      0.52      0.57      2726\n",
      "\n",
      "    accuracy                           0.80     10565\n",
      "   macro avg       0.74      0.71      0.72     10565\n",
      "weighted avg       0.79      0.80      0.79     10565\n",
      "\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for ngram in [(1,3),(1,4)]:\n",
    "    for feat in [100000, 150000, 300000]:\n",
    "        check_tfidf(ngram, feat)    \n",
    "        print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With stopwords removal still no preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.6.2-py3-none-any.whl (1.5 MB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\n.babakov\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from nltk) (4.48.2)\n",
      "Requirement already satisfied: regex in c:\\users\\n.babakov\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from nltk) (2020.7.14)\n",
      "Requirement already satisfied: click in c:\\users\\n.babakov\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\n.babakov\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from nltk) (0.16.0)\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.6.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script nltk.exe is installed in 'C:\\Users\\N.Babakov\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\N.Babakov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "russian_stopwords = stopwords.words(\"russian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngram_range (1, 3), max_features 100000\n",
      "[0.79489059 0.79719401 0.79817811 0.79959164 0.79760222] 0.7974913137050577\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87      7839\n",
      "           1       0.64      0.52      0.57      2726\n",
      "\n",
      "    accuracy                           0.80     10565\n",
      "   macro avg       0.74      0.71      0.72     10565\n",
      "weighted avg       0.79      0.80      0.79     10565\n",
      "\n",
      "====================================================================================================\n",
      "ngram_range (1, 3), max_features 300000\n",
      "[0.79939273 0.8014344  0.80419873 0.80430344 0.80487933] 0.8028417273740798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87      7839\n",
      "           1       0.63      0.54      0.58      2726\n",
      "\n",
      "    accuracy                           0.80     10565\n",
      "   macro avg       0.74      0.71      0.72     10565\n",
      "weighted avg       0.79      0.80      0.79     10565\n",
      "\n",
      "====================================================================================================\n",
      "ngram_range (1, 4), max_features 100000\n",
      "[0.79557114 0.79598995 0.80058636 0.79901576 0.8013193 ] 0.7984965021612158\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.87      7839\n",
      "           1       0.63      0.52      0.57      2726\n",
      "\n",
      "    accuracy                           0.80     10565\n",
      "   macro avg       0.74      0.71      0.72     10565\n",
      "weighted avg       0.79      0.80      0.79     10565\n",
      "\n",
      "====================================================================================================\n",
      "ngram_range (1, 4), max_features 300000\n",
      "[0.79944508 0.8009109  0.80252343 0.80419873 0.8004293 ] 0.8015014883410956\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.87      7839\n",
      "           1       0.63      0.53      0.57      2726\n",
      "\n",
      "    accuracy                           0.80     10565\n",
      "   macro avg       0.74      0.71      0.72     10565\n",
      "weighted avg       0.79      0.80      0.79     10565\n",
      "\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for ngram in [(1,3),(1,4)]:\n",
    "    for feat in [100000, 300000]:\n",
    "        check_tfidf(russian_stopwords, ngram, feat)    \n",
    "        print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pymystem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> import pymorphy2\n",
    "import re\n",
    ">>> morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['мама', 'мыла']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = re.sub(\"[^а-яА-Я]\",\" \",\"мама23663 мыла /!\")\n",
    "t = re.sub(\" +\",\" \",t)\n",
    "t = t.split()\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parse(word='бреет', tag=OpencorporaTag('VERB,impf,tran sing,3per,pres,indc'), normal_form='брить', score=1.0, methods_stack=((DictionaryAnalyzer(), 'бреет', 569, 5),))]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morph.parse(\"бреет\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "from string import punctuation\n",
    "from tqdm import tqdm\n",
    "mystem = Mystem() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'мама мыло'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    \n",
    "    text = re.sub(\"[^а-яА-Я]\",\" \",text)\n",
    "    text = re.sub(\" +\",\" \",text)\n",
    "    text = text.split()\n",
    "\n",
    "    tokens = [morph.parse(w)[0].normal_form for w in text]\n",
    "    tokens = [token for token in tokens if token not in russian_stopwords\\\n",
    "              and token != \" \" \\\n",
    "              and token.strip() not in punctuation]\n",
    "    \n",
    "    text = \" \".join(tokens)\n",
    "    \n",
    "    return text\n",
    "\n",
    "preprocess_text(\"мама23663 мыла /!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 95507/95507 [05:20<00:00, 297.59it/s]\n"
     ]
    }
   ],
   "source": [
    "processed = []\n",
    "for t in tqdm(train_val['text'].tolist()):\n",
    "    pr = preprocess_text(t)\n",
    "    processed.append(pr)\n",
    "    \n",
    "train_val['processed'] = processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 10565/10565 [00:35<00:00, 297.96it/s]\n"
     ]
    }
   ],
   "source": [
    "processed = []\n",
    "for t in tqdm(df_test['text'].tolist()):\n",
    "    pr = preprocess_text(t)\n",
    "    processed.append(pr)\n",
    "df_test['processed'] = processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngram_range (1, 3), max_features 100000\n",
      "[0.81310858 0.81384148 0.81681587 0.81749647 0.82262709] 0.8167778969681422\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88      7839\n",
      "           1       0.67      0.58      0.62      2726\n",
      "\n",
      "    accuracy                           0.82     10565\n",
      "   macro avg       0.77      0.74      0.75     10565\n",
      "weighted avg       0.81      0.82      0.81     10565\n",
      "\n",
      "====================================================================================================\n",
      "ngram_range (1, 3), max_features 300000\n",
      "[0.81902419 0.82106586 0.81885765 0.82142296 0.82241767] 0.8205576661950378\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.88      7839\n",
      "           1       0.68      0.61      0.64      2726\n",
      "\n",
      "    accuracy                           0.83     10565\n",
      "   macro avg       0.78      0.75      0.76     10565\n",
      "weighted avg       0.82      0.83      0.82     10565\n",
      "\n",
      "====================================================================================================\n",
      "ngram_range (1, 4), max_features 100000\n",
      "[0.81143336 0.81316093 0.81639705 0.81770588 0.81582116] 0.8149036742130431\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88      7839\n",
      "           1       0.68      0.58      0.63      2726\n",
      "\n",
      "    accuracy                           0.82     10565\n",
      "   macro avg       0.77      0.74      0.75     10565\n",
      "weighted avg       0.81      0.82      0.82     10565\n",
      "\n",
      "====================================================================================================\n",
      "ngram_range (1, 4), max_features 300000\n",
      "[0.81525495 0.8157261  0.82356945 0.81911942 0.82241767] 0.8192175176058939\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.88      7839\n",
      "           1       0.68      0.60      0.64      2726\n",
      "\n",
      "    accuracy                           0.82     10565\n",
      "   macro avg       0.77      0.75      0.76     10565\n",
      "weighted avg       0.82      0.82      0.82     10565\n",
      "\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for ngram in [(1,3),(1,4)]:\n",
    "    for feat in [100000, 300000]:\n",
    "        check_tfidf(russian_stopwords, ngram, feat, 'processed')    \n",
    "        print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ngram_range (1, 3), max_features 100000\n",
    "[0.81310858 0.81384148 0.81681587 0.81749647 0.82262709] 0.8167778969681422\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.86      0.90      0.88      7839\n",
    "           1       0.67      0.58      0.62      2726\n",
    "\n",
    "    accuracy                           0.82     10565\n",
    "   macro avg       0.77      0.74      0.75     10565\n",
    "weighted avg       0.81      0.82      0.81     10565\n",
    "\n",
    "====================================================================================================\n",
    "ngram_range (1, 3), max_features 300000\n",
    "[0.81902419 0.82106586 0.81885765 0.82142296 0.82241767] 0.8205576661950378\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.87      0.90      0.88      7839\n",
    "           1       0.68      0.61      0.64      2726\n",
    "\n",
    "    accuracy                           0.83     10565\n",
    "   macro avg       0.78      0.75      0.76     10565\n",
    "weighted avg       0.82      0.83      0.82     10565\n",
    "\n",
    "====================================================================================================\n",
    "ngram_range (1, 4), max_features 100000\n",
    "[0.81143336 0.81316093 0.81639705 0.81770588 0.81582116] 0.8149036742130431\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.86      0.90      0.88      7839\n",
    "           1       0.68      0.58      0.63      2726\n",
    "\n",
    "    accuracy                           0.82     10565\n",
    "   macro avg       0.77      0.74      0.75     10565\n",
    "weighted avg       0.81      0.82      0.82     10565\n",
    "\n",
    "====================================================================================================\n",
    "ngram_range (1, 4), max_features 300000\n",
    "[0.81525495 0.8157261  0.82356945 0.81911942 0.82241767] 0.8192175176058939\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.87      0.90      0.88      7839\n",
    "           1       0.68      0.60      0.64      2726\n",
    "\n",
    "    accuracy                           0.82     10565\n",
    "   macro avg       0.77      0.75      0.76     10565\n",
    "weighted avg       0.82      0.82      0.82     10565"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngram_range (1, 3), max_features 150000\n",
      "fitting ...\n"
     ]
    }
   ],
   "source": [
    "def check_SVM(ngram_range=(1, 3), max_features=150000, kernel = 'linear'):\n",
    "    \n",
    "    print(\"ngram_range {}, max_features {}\".format(ngram_range, max_features))\n",
    "    \n",
    "    text_transformer = TfidfVectorizer(stop_words=russian_stopwords, ngram_range=ngram_range, lowercase=True, max_features=max_features)\n",
    "    X_train_text = text_transformer.fit_transform(train_val['processed'].tolist())\n",
    "    \n",
    "    X_test_text = text_transformer.transform(df_test['processed'])\n",
    "\n",
    "#     logit = LogisticRegression(C=5e1, solver='lbfgs', multi_class='multinomial', random_state=17, n_jobs=4)\n",
    "    logit = SVC(kernel = kernel)\n",
    "    print(\"fitting ...\")\n",
    "    logit.fit(X_train_text, train_val['inappropriate'])\n",
    "    test_preds = logit.predict(X_test_text)\n",
    "    print(classification_report(df_test['inappropriate'], test_preds))\n",
    "    \n",
    "    check_SVM\n",
    "    \n",
    "check_SVM()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
