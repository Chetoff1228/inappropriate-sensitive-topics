{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mutlti logreg sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10) (1000,)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, n_classes=3, random_state=1)\n",
    "# summarize the dataset\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.89149379, -0.39847585,  1.63856893,  0.01647165,  1.51892395,\n",
       "        -3.52651223,  1.80998823,  0.58810926, -0.02542177, -0.52835426],\n",
       "       [ 1.86913773, -0.56336215,  2.03411807,  0.38669445, -0.09584042,\n",
       "        -2.92724017,  0.73921674, -0.55633   , -0.27340013,  0.72129251],\n",
       "       [ 1.95259701, -2.83144572,  0.19055535, -0.66388697,  0.19159093,\n",
       "        -1.8591214 , -0.10150205, -0.60957741, -2.07750191, -1.75469982],\n",
       "       [-0.67042514, -0.69082031,  0.59354753, -0.06270367,  2.37357676,\n",
       "        -0.52106039,  0.42872513, -0.26851085,  0.49226161, -1.34383965],\n",
       "       [-1.39890137, -0.71522959, -0.6774507 ,  0.39153885, -0.45832391,\n",
       "         2.17898372, -1.88550244, -0.96686613, -0.42588787, -0.20782615],\n",
       "       [-2.94551044, -0.79851493, -1.92807818, -0.11749422,  3.75941261,\n",
       "         2.55924496, -0.71375699,  0.87323395,  0.26641973, -3.52801155],\n",
       "       [-0.99746413, -1.35338763, -1.50586396, -1.73258977,  3.66110299,\n",
       "         0.44739896,  1.27005199,  0.76439032,  0.10839262, -3.74038228],\n",
       "       [-0.26028138,  0.51739762,  1.78389329,  2.51998179,  1.46572279,\n",
       "        -1.50616812, -0.68426509,  0.64095725,  0.27620903,  0.3131776 ],\n",
       "       [ 1.00862774, -4.44379822, -0.23197007, -1.01409556, -0.10921532,\n",
       "        -0.17692105, -1.63553575, -2.32000882, -2.71351248, -2.35483141],\n",
       "       [ 2.83315115, -2.64365032,  3.93779191,  3.74756698,  4.70060001,\n",
       "        -7.08044923,  0.01118705,  1.61033554, -2.04795128, -2.74329857]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 2, 0, 2, 2, 2, 0, 0])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.681 (0.042)\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, n_classes=3, random_state=1)\n",
    "# define the multinomial logistic regression model\n",
    "model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "# define the model evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate the model and collect the scores\n",
    "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report the model performance\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "\n",
    "# import eli5\n",
    "\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_multilabel_classification(n_classes=3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3., 6., 1., ..., 1., 5., 0.],\n",
       "       [3., 5., 5., ..., 1., 1., 1.],\n",
       "       [3., 3., 5., ..., 0., 2., 1.],\n",
       "       ...,\n",
       "       [3., 7., 3., ..., 2., 4., 2.],\n",
       "       [7., 2., 1., ..., 1., 1., 1.],\n",
       "       [3., 5., 3., ..., 1., 2., 4.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0],\n",
       "       [0, 1, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RST = 0\n",
    "df = pd.read_csv(\"./compare_manual_manuallVSsemiauto/train_manualVSsemiauto_rst_{}.csv\".format(RST))\n",
    "df_val = pd.read_csv(\"./compare_manual_manuallVSsemiauto/val_manual_only_rst_{}.csv\".format(RST))\n",
    "df_test = pd.read_csv(\"./compare_manual_manuallVSsemiauto/test_manual_only_rst_{}.csv\".format(RST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['offline_crime',\n",
       " 'online_crime',\n",
       " 'drugs',\n",
       " 'gambling',\n",
       " 'pornography',\n",
       " 'prostitution',\n",
       " 'slavery',\n",
       " 'suicide',\n",
       " 'terrorism',\n",
       " 'weapons',\n",
       " 'body_shaming',\n",
       " 'health_shaming',\n",
       " 'politics',\n",
       " 'racism',\n",
       " 'religion',\n",
       " 'sexual_minorities',\n",
       " 'sexism',\n",
       " 'social_injustice',\n",
       " 'none']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "necessary_columns = list(df.columns)[1:] \n",
    "topics_list = necessary_columns + ['none']\n",
    "topics_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(dataframe):\n",
    "    labels =[]\n",
    "    for i, el in dataframe.iterrows():\n",
    "        current_sample_labels = []\n",
    "        any_class = False\n",
    "        for clm in necessary_columns:\n",
    "            if el[clm] == 1:\n",
    "                any_class = True\n",
    "                current_sample_labels.append(clm)\n",
    "        if any_class == False:\n",
    "            current_sample_labels.append(\"none\")\n",
    "        current_sample_labels = ','.join(current_sample_labels)\n",
    "        labels.append(current_sample_labels)\n",
    "    return labels\n",
    "train_labels = get_labels(df)\n",
    "val_labels = get_labels(df_val)\n",
    "test_labels = get_labels(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['offline_crime', 'none', 'offline_crime', 'offline_crime', 'offline_crime']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'text':list(df['text']), 'labels':train_labels})\n",
    "df_val = pd.DataFrame({'text':list(df_val['text']), 'labels':val_labels})\n",
    "df_test = pd.DataFrame({'text':list(df_test['text']), 'labels':test_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = dict()\n",
    "mapping['none'] = 0\n",
    "\n",
    "for label in train_labels:\n",
    "    if label not in mapping:\n",
    "        mapping[label] = len(mapping)\n",
    "\n",
    "for label in test_labels:\n",
    "    if label not in mapping:\n",
    "        mapping[label] = len(mapping)\n",
    "        \n",
    "for label in val_labels:\n",
    "    if label not in mapping:\n",
    "        mapping[label] = len(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'] = df['labels'].apply(lambda x: mapping[x])\n",
    "df_test['class'] = df_test['labels'].apply(lambda x: mapping[x])\n",
    "df_val['class'] = df_val['labels'].apply(lambda x: mapping[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ман, можно же ведь и сабцы навернуть!А можно и...</td>\n",
       "      <td>offline_crime</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Чтобы не было на них постороннего давления... ...</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>С 12 лет на трое суток, а потом пять лет тюрьм...</td>\n",
       "      <td>offline_crime</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>там и смертная казнь есть за некоторые преступ...</td>\n",
       "      <td>offline_crime</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Есть убивство во благо . И каждый настоящий че...</td>\n",
       "      <td>offline_crime</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text         labels  class\n",
       "0  Ман, можно же ведь и сабцы навернуть!А можно и...  offline_crime      1\n",
       "1  Чтобы не было на них постороннего давления... ...           none      0\n",
       "2  С 12 лет на трое суток, а потом пять лет тюрьм...  offline_crime      1\n",
       "3  там и смертная казнь есть за некоторые преступ...  offline_crime      1\n",
       "4  Есть убивство во благо . И каждый настоящий че...  offline_crime      1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val = pd.concat([df,df_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ман, можно же ведь и сабцы навернуть!А можно и...</td>\n",
       "      <td>offline_crime</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Чтобы не было на них постороннего давления... ...</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>С 12 лет на трое суток, а потом пять лет тюрьм...</td>\n",
       "      <td>offline_crime</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>там и смертная казнь есть за некоторые преступ...</td>\n",
       "      <td>offline_crime</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Есть убивство во благо . И каждый настоящий че...</td>\n",
       "      <td>offline_crime</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text         labels  class\n",
       "0  Ман, можно же ведь и сабцы навернуть!А можно и...  offline_crime      1\n",
       "1  Чтобы не было на них постороннего давления... ...           none      0\n",
       "2  С 12 лет на трое суток, а потом пять лет тюрьм...  offline_crime      1\n",
       "3  там и смертная казнь есть за некоторые преступ...  offline_crime      1\n",
       "4  Есть убивство во благо . И каждый настоящий че...  offline_crime      1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Стреляют по ногам чтобы не убить а там артерия...</td>\n",
       "      <td>offline_crime</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Если тебе дали в морду, а ты пырнул ножом - до...</td>\n",
       "      <td>offline_crime</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Какие доказательства нужны, чтобы суд вынес об...</td>\n",
       "      <td>offline_crime</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>протокол составить на родителей. И выписать им...</td>\n",
       "      <td>offline_crime</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Правда ли что коллекторы могут по законы силой...</td>\n",
       "      <td>offline_crime</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text         labels  class\n",
       "0  Стреляют по ногам чтобы не убить а там артерия...  offline_crime      1\n",
       "1  Если тебе дали в морду, а ты пырнул ножом - до...  offline_crime      1\n",
       "2  Какие доказательства нужны, чтобы суд вынес об...  offline_crime      1\n",
       "3  протокол составить на родителей. И выписать им...  offline_crime      1\n",
       "4  Правда ли что коллекторы могут по законы силой...  offline_crime      1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_encoder = OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trval_list = np.array(train_val['class'].tolist())\n",
    "trval_list  = trval_list.reshape(-1, 1)\n",
    "trval_list = onehot_encoder.fit_transform(trval_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = np.array(df_test['class'].tolist())\n",
    "test_list  = test_list.reshape(-1, 1)\n",
    "test_list = onehot_encoder.fit_transform(test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-idf logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/kashnitsky/logistic-regression-tf-idf-baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\N.Babakov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'мама мыло'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "import re\n",
    "\n",
    "\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "from pymystem3 import Mystem\n",
    "from string import punctuation\n",
    "from tqdm import tqdm\n",
    "mystem = Mystem() \n",
    "\n",
    "def preprocess_text(text):\n",
    "    \n",
    "    text = re.sub(\"[^а-яА-Я]\",\" \",text)\n",
    "    text = re.sub(\" +\",\" \",text)\n",
    "    text = text.split()\n",
    "\n",
    "    tokens = [morph.parse(w)[0].normal_form for w in text]\n",
    "    tokens = [token for token in tokens if token not in russian_stopwords\\\n",
    "              and token != \" \" \\\n",
    "              and token.strip() not in punctuation]\n",
    "    \n",
    "    text = \" \".join(tokens)\n",
    "    \n",
    "    return text\n",
    "\n",
    "preprocess_text(\"мама23663 мыла /!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 34542/34542 [02:33<00:00, 224.34it/s]\n"
     ]
    }
   ],
   "source": [
    "processed = []\n",
    "for t in tqdm(train_val['text'].tolist()):\n",
    "    pr = preprocess_text(t)\n",
    "    processed.append(pr)\n",
    "    \n",
    "train_val['processed'] = processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1585/1585 [00:05<00:00, 310.61it/s]\n"
     ]
    }
   ],
   "source": [
    "processed = []\n",
    "for t in tqdm(df_test['text'].tolist()):\n",
    "    pr = preprocess_text(t)\n",
    "    processed.append(pr)\n",
    "df_test['processed'] = processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_vaiables_id2topic_dict = {val:key for key, val in mapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'none',\n",
       " 1: 'offline_crime',\n",
       " 2: 'online_crime',\n",
       " 3: 'drugs',\n",
       " 4: 'gambling',\n",
       " 5: 'pornography',\n",
       " 6: 'prostitution',\n",
       " 7: 'slavery',\n",
       " 8: 'suicide',\n",
       " 9: 'terrorism',\n",
       " 10: 'weapons',\n",
       " 11: 'body_shaming',\n",
       " 12: 'health_shaming',\n",
       " 13: 'politics',\n",
       " 14: 'racism',\n",
       " 15: 'religion',\n",
       " 16: 'sexual_minorities',\n",
       " 17: 'sexism',\n",
       " 18: 'social_injustice',\n",
       " 19: 'sexual_minorities,sexism,social_injustice',\n",
       " 20: 'offline_crime,religion,sexism,social_injustice',\n",
       " 21: 'politics,racism,sexism,social_injustice',\n",
       " 22: 'sexism,social_injustice',\n",
       " 23: 'slavery,politics,sexism,social_injustice',\n",
       " 24: 'politics,sexism',\n",
       " 25: 'politics,sexism,social_injustice',\n",
       " 26: 'slavery,sexism',\n",
       " 27: 'slavery,sexism,social_injustice',\n",
       " 28: 'body_shaming,social_injustice',\n",
       " 29: 'prostitution,sexism',\n",
       " 30: 'prostitution,sexism,social_injustice',\n",
       " 31: 'offline_crime,pornography,sexism,social_injustice',\n",
       " 32: 'pornography,sexism,social_injustice',\n",
       " 33: 'prostitution,social_injustice',\n",
       " 34: 'politics,social_injustice',\n",
       " 35: 'pornography,body_shaming,social_injustice',\n",
       " 36: 'offline_crime,social_injustice',\n",
       " 37: 'politics,racism,religion,sexual_minorities',\n",
       " 38: 'pornography,slavery,religion,sexual_minorities,social_injustice',\n",
       " 39: 'religion,sexual_minorities,social_injustice',\n",
       " 40: 'politics,racism,sexual_minorities,social_injustice',\n",
       " 41: 'offline_crime,politics,racism,sexual_minorities,social_injustice',\n",
       " 42: 'pornography,politics,sexual_minorities,social_injustice',\n",
       " 43: 'politics,sexual_minorities,social_injustice',\n",
       " 44: 'pornography,prostitution,sexual_minorities,social_injustice',\n",
       " 45: 'prostitution,sexual_minorities,social_injustice',\n",
       " 46: 'pornography,sexual_minorities,social_injustice',\n",
       " 47: 'pornography,sexual_minorities',\n",
       " 48: 'sexual_minorities,social_injustice',\n",
       " 49: 'offline_crime,terrorism,racism,social_injustice',\n",
       " 50: 'slavery,social_injustice',\n",
       " 51: 'pornography,slavery,social_injustice',\n",
       " 52: 'racism,social_injustice',\n",
       " 53: 'politics,racism,social_injustice',\n",
       " 54: 'politics,racism',\n",
       " 55: 'terrorism,politics,racism,religion,social_injustice',\n",
       " 56: 'politics,racism,religion,social_injustice',\n",
       " 57: 'racism,religion',\n",
       " 58: 'terrorism,racism,religion',\n",
       " 59: 'terrorism,racism',\n",
       " 60: 'terrorism,racism,religion,social_injustice',\n",
       " 61: 'terrorism,religion',\n",
       " 62: 'politics,religion',\n",
       " 63: 'pornography,religion',\n",
       " 64: 'weapons,politics,racism',\n",
       " 65: 'weapons,racism',\n",
       " 66: 'weapons,politics',\n",
       " 67: 'drugs,terrorism,politics,racism',\n",
       " 68: 'terrorism,politics,racism,social_injustice',\n",
       " 69: 'terrorism,politics,racism',\n",
       " 70: 'slavery,racism,social_injustice',\n",
       " 71: 'slavery,politics,racism,social_injustice',\n",
       " 72: 'prostitution,politics,racism',\n",
       " 73: 'pornography,politics,racism',\n",
       " 74: 'pornography,politics,racism,social_injustice',\n",
       " 75: 'offline_crime,politics,racism,social_injustice',\n",
       " 76: 'offline_crime,politics,racism',\n",
       " 77: 'prostitution,health_shaming,racism,social_injustice',\n",
       " 78: 'weapons,racism,social_injustice',\n",
       " 79: 'offline_crime,terrorism,social_injustice',\n",
       " 80: 'terrorism,racism,social_injustice',\n",
       " 81: 'suicide,racism,social_injustice',\n",
       " 82: 'prostitution,racism,social_injustice',\n",
       " 83: 'pornography,racism',\n",
       " 84: 'offline_crime,racism,social_injustice',\n",
       " 85: 'body_shaming,racism',\n",
       " 86: 'offline_crime,politics',\n",
       " 87: 'offline_crime,politics,social_injustice',\n",
       " 88: 'slavery,politics,social_injustice',\n",
       " 89: 'slavery,politics',\n",
       " 90: 'health_shaming,politics,social_injustice',\n",
       " 91: 'body_shaming,politics,social_injustice',\n",
       " 92: 'terrorism,politics',\n",
       " 93: 'terrorism,politics,social_injustice',\n",
       " 94: 'offline_crime,slavery,politics,social_injustice',\n",
       " 95: 'gambling,politics,social_injustice',\n",
       " 96: 'drugs,social_injustice',\n",
       " 97: 'drugs,politics,social_injustice',\n",
       " 98: 'body_shaming,health_shaming,social_injustice',\n",
       " 99: 'drugs,health_shaming,social_injustice',\n",
       " 100: 'health_shaming,social_injustice',\n",
       " 101: 'prostitution,body_shaming,social_injustice',\n",
       " 102: 'offline_crime,drugs,body_shaming,social_injustice',\n",
       " 103: 'drugs,body_shaming,social_injustice',\n",
       " 104: 'offline_crime,body_shaming,social_injustice',\n",
       " 105: 'offline_crime,drugs,weapons,social_injustice',\n",
       " 106: 'weapons,social_injustice',\n",
       " 107: 'offline_crime,pornography,suicide,social_injustice',\n",
       " 108: 'suicide,social_injustice',\n",
       " 109: 'prostitution,slavery,social_injustice',\n",
       " 110: 'offline_crime,drugs,slavery,social_injustice',\n",
       " 111: 'gambling,social_injustice',\n",
       " 112: 'pornography,prostitution',\n",
       " 113: 'pornography,prostitution,social_injustice',\n",
       " 114: 'drugs,prostitution,social_injustice',\n",
       " 115: 'pornography,social_injustice',\n",
       " 116: 'offline_crime,pornography,social_injustice',\n",
       " 117: 'offline_crime,drugs,social_injustice',\n",
       " 118: 'prostitution,body_shaming',\n",
       " 119: 'prostitution,body_shaming,sexism',\n",
       " 120: 'offline_crime,terrorism,politics,racism',\n",
       " 121: 'online_crime,politics,racism',\n",
       " 122: 'prostitution,politics',\n",
       " 123: 'sexual_minorities,sexism',\n",
       " 124: 'prostitution,racism,sexism',\n",
       " 125: 'health_shaming,religion',\n",
       " 126: 'drugs,racism',\n",
       " 127: 'offline_crime,sexual_minorities',\n",
       " 128: 'offline_crime,slavery,racism',\n",
       " 129: 'pornography,sexism',\n",
       " 130: 'slavery,racism',\n",
       " 131: 'pornography,politics,sexual_minorities',\n",
       " 132: 'pornography,politics',\n",
       " 133: 'offline_crime,pornography,prostitution,sexual_minorities',\n",
       " 134: 'prostitution,racism',\n",
       " 135: 'prostitution,slavery,sexism',\n",
       " 136: 'prostitution,slavery',\n",
       " 137: 'pornography,body_shaming,sexism',\n",
       " 138: 'pornography,body_shaming',\n",
       " 139: 'offline_crime,drugs,politics',\n",
       " 140: 'offline_crime,slavery',\n",
       " 141: 'offline_crime,weapons',\n",
       " 142: 'pornography,religion,sexual_minorities',\n",
       " 143: 'offline_crime,pornography,sexual_minorities',\n",
       " 144: 'offline_crime,pornography',\n",
       " 145: 'slavery,politics,racism',\n",
       " 146: 'offline_crime,slavery,politics,racism',\n",
       " 147: 'offline_crime,drugs',\n",
       " 148: 'prostitution,sexual_minorities',\n",
       " 149: 'politics,racism,religion',\n",
       " 150: 'pornography,prostitution,sexism',\n",
       " 151: 'body_shaming,health_shaming',\n",
       " 152: 'pornography,prostitution,sexual_minorities,sexism',\n",
       " 153: 'prostitution,sexual_minorities,sexism',\n",
       " 154: 'offline_crime,pornography,sexual_minorities,sexism',\n",
       " 155: 'pornography,sexual_minorities,sexism',\n",
       " 156: 'suicide,sexism',\n",
       " 157: 'religion,sexism',\n",
       " 158: 'pornography,body_shaming,racism,sexism',\n",
       " 159: 'body_shaming,racism,sexism',\n",
       " 160: 'pornography,racism,sexism',\n",
       " 161: 'pornography,prostitution,terrorism,sexism',\n",
       " 162: 'body_shaming,politics,sexism',\n",
       " 163: 'terrorism,politics,sexism',\n",
       " 164: 'offline_crime,pornography,sexism',\n",
       " 165: 'prostitution,health_shaming,sexism',\n",
       " 166: 'pornography,health_shaming,sexism',\n",
       " 167: 'health_shaming,sexual_minorities',\n",
       " 168: 'health_shaming,sexism',\n",
       " 169: 'body_shaming,sexism',\n",
       " 170: 'offline_crime,pornography,prostitution',\n",
       " 171: 'offline_crime,gambling,pornography,slavery,sexism',\n",
       " 172: 'pornography,prostitution,slavery,sexism',\n",
       " 173: 'offline_crime,slavery,sexism',\n",
       " 174: 'drugs,prostitution,sexism',\n",
       " 175: 'offline_crime,prostitution,sexism',\n",
       " 176: 'drugs,sexism',\n",
       " 177: 'offline_crime,sexism',\n",
       " 178: 'drugs,pornography',\n",
       " 179: 'terrorism,sexual_minorities',\n",
       " 180: 'pornography,prostitution,sexual_minorities',\n",
       " 181: 'online_crime,pornography',\n",
       " 182: 'offline_crime,terrorism,racism',\n",
       " 183: 'offline_crime,health_shaming',\n",
       " 184: 'racism,sexual_minorities',\n",
       " 185: 'drugs,sexual_minorities',\n",
       " 186: 'offline_crime,prostitution,health_shaming',\n",
       " 187: 'pornography,prostitution,religion,sexual_minorities',\n",
       " 188: 'slavery,politics,racism,sexual_minorities',\n",
       " 189: 'pornography,politics,racism,sexual_minorities',\n",
       " 190: 'politics,racism,sexual_minorities',\n",
       " 191: 'pornography,slavery,racism,sexual_minorities',\n",
       " 192: 'pornography,racism,sexual_minorities',\n",
       " 193: 'politics,sexual_minorities',\n",
       " 194: 'pornography,prostitution,politics',\n",
       " 195: 'slavery,sexual_minorities',\n",
       " 196: 'offline_crime,pornography,health_shaming,sexual_minorities',\n",
       " 197: 'pornography,health_shaming,sexual_minorities',\n",
       " 198: 'pornography,body_shaming,sexual_minorities',\n",
       " 199: 'online_crime,pornography,sexual_minorities',\n",
       " 200: 'weapons,sexual_minorities',\n",
       " 201: 'body_shaming,sexual_minorities',\n",
       " 202: 'pornography,prostitution,body_shaming',\n",
       " 203: 'pornography,suicide',\n",
       " 204: 'pornography,slavery,sexual_minorities',\n",
       " 205: 'offline_crime,drugs,prostitution,sexual_minorities',\n",
       " 206: 'offline_crime,prostitution',\n",
       " 207: 'offline_crime,drugs,pornography,sexual_minorities',\n",
       " 208: 'drugs,pornography,sexual_minorities',\n",
       " 209: 'online_crime,sexual_minorities',\n",
       " 210: 'drugs,suicide',\n",
       " 211: 'offline_crime,racism',\n",
       " 212: 'drugs,politics,racism',\n",
       " 213: 'prostitution,religion',\n",
       " 214: 'online_crime,pornography,religion',\n",
       " 215: 'pornography,health_shaming',\n",
       " 216: 'offline_crime,religion',\n",
       " 217: 'terrorism,weapons,politics,racism,religion',\n",
       " 218: 'weapons,politics,racism,religion',\n",
       " 219: 'offline_crime,racism,religion',\n",
       " 220: 'drugs,racism,religion',\n",
       " 221: 'offline_crime,drugs,racism,religion',\n",
       " 222: 'health_shaming,racism,religion',\n",
       " 223: 'slavery,racism,religion',\n",
       " 224: 'offline_crime,terrorism,religion',\n",
       " 225: 'terrorism,politics,religion',\n",
       " 226: 'slavery,politics,religion',\n",
       " 227: 'weapons,health_shaming,religion',\n",
       " 228: 'drugs,health_shaming,religion',\n",
       " 229: 'body_shaming,religion',\n",
       " 230: 'drugs,weapons,religion',\n",
       " 231: 'weapons,religion',\n",
       " 232: 'suicide,religion',\n",
       " 233: 'slavery,religion',\n",
       " 234: 'pornography,prostitution,religion',\n",
       " 235: 'drugs,pornography,religion',\n",
       " 236: 'offline_crime,pornography,religion',\n",
       " 237: 'offline_crime,drugs,religion',\n",
       " 238: 'drugs,religion',\n",
       " 239: 'terrorism,weapons,politics,racism',\n",
       " 240: 'pornography,terrorism,politics,racism',\n",
       " 241: 'pornography,slavery,politics,racism',\n",
       " 242: 'offline_crime,pornography,politics,racism',\n",
       " 243: 'slavery,terrorism,racism',\n",
       " 244: 'online_crime,racism',\n",
       " 245: 'gambling,racism',\n",
       " 246: 'pornography,slavery,racism',\n",
       " 247: 'drugs,prostitution,health_shaming,racism',\n",
       " 248: 'health_shaming,racism',\n",
       " 249: 'slavery,body_shaming,racism',\n",
       " 250: 'offline_crime,slavery,terrorism,racism',\n",
       " 251: 'online_crime,terrorism,racism',\n",
       " 252: 'online_crime,pornography,prostitution,racism',\n",
       " 253: 'pornography,prostitution,racism',\n",
       " 254: 'offline_crime,pornography,racism',\n",
       " 255: 'offline_crime,prostitution,slavery',\n",
       " 256: 'health_shaming,politics',\n",
       " 257: 'weapons,health_shaming,politics',\n",
       " 258: 'pornography,health_shaming,politics',\n",
       " 259: 'pornography,body_shaming,politics',\n",
       " 260: 'body_shaming,politics',\n",
       " 261: 'online_crime,weapons',\n",
       " 262: 'terrorism,weapons,politics',\n",
       " 263: 'offline_crime,terrorism,weapons,politics',\n",
       " 264: 'suicide,weapons,politics',\n",
       " 265: 'offline_crime,weapons,politics',\n",
       " 266: 'gambling,terrorism,politics',\n",
       " 267: 'offline_crime,terrorism,politics',\n",
       " 268: 'online_crime,politics',\n",
       " 269: 'suicide,politics',\n",
       " 270: 'offline_crime,slavery,politics',\n",
       " 271: 'drugs,gambling,politics',\n",
       " 272: 'gambling,politics',\n",
       " 273: 'offline_crime,pornography,politics',\n",
       " 274: 'drugs,politics',\n",
       " 275: 'offline_crime,pornography,terrorism,weapons',\n",
       " 276: 'weapons,health_shaming',\n",
       " 277: 'offline_crime,terrorism',\n",
       " 278: 'offline_crime,body_shaming',\n",
       " 279: 'suicide,health_shaming',\n",
       " 280: 'offline_crime,weapons,health_shaming',\n",
       " 281: 'drugs,prostitution',\n",
       " 282: 'offline_crime,online_crime',\n",
       " 283: 'drugs,body_shaming,health_shaming',\n",
       " 284: 'offline_crime,body_shaming,health_shaming',\n",
       " 285: 'offline_crime,drugs,suicide,health_shaming',\n",
       " 286: 'drugs,gambling,health_shaming',\n",
       " 287: 'pornography,slavery,health_shaming',\n",
       " 288: 'slavery,health_shaming',\n",
       " 289: 'offline_crime,pornography,prostitution,health_shaming',\n",
       " 290: 'pornography,prostitution,health_shaming',\n",
       " 291: 'prostitution,health_shaming',\n",
       " 292: 'offline_crime,pornography,health_shaming',\n",
       " 293: 'drugs,health_shaming',\n",
       " 294: 'offline_crime,drugs,health_shaming',\n",
       " 295: 'weapons,body_shaming',\n",
       " 296: 'offline_crime,prostitution,suicide,body_shaming',\n",
       " 297: 'drugs,body_shaming',\n",
       " 298: 'online_crime,pornography,prostitution',\n",
       " 299: 'offline_crime,drugs,pornography,prostitution,slavery,weapons',\n",
       " 300: 'gambling,weapons',\n",
       " 301: 'drugs,weapons',\n",
       " 302: 'pornography,weapons',\n",
       " 303: 'offline_crime,drugs,weapons',\n",
       " 304: 'pornography,terrorism',\n",
       " 305: 'offline_crime,suicide',\n",
       " 306: 'online_crime,pornography,slavery',\n",
       " 307: 'offline_crime,pornography,slavery',\n",
       " 308: 'pornography,slavery',\n",
       " 309: 'online_crime,gambling',\n",
       " 310: 'offline_crime,drugs,pornography,prostitution',\n",
       " 311: 'drugs,pornography,prostitution',\n",
       " 312: 'online_crime,prostitution',\n",
       " 313: 'offline_crime,drugs,pornography',\n",
       " 314: 'offline_crime,online_crime,pornography',\n",
       " 315: 'offline_crime,online_crime,drugs',\n",
       " 316: 'racism,sexism',\n",
       " 317: 'weapons,sexism',\n",
       " 318: 'online_crime,social_injustice',\n",
       " 319: 'pornography,suicide,sexual_minorities',\n",
       " 320: 'online_crime,body_shaming',\n",
       " 321: 'offline_crime,health_shaming,politics',\n",
       " 322: 'politics,religion,social_injustice',\n",
       " 323: 'religion,social_injustice',\n",
       " 324: 'body_shaming,sexism,social_injustice',\n",
       " 325: 'racism,religion,social_injustice',\n",
       " 326: 'prostitution,politics,racism,social_injustice',\n",
       " 327: 'pornography,racism,social_injustice',\n",
       " 328: 'online_crime,terrorism',\n",
       " 329: 'pornography,politics,sexism',\n",
       " 330: 'pornography,prostitution,racism,sexual_minorities',\n",
       " 331: 'pornography,racism,religion',\n",
       " 332: 'offline_crime,politics,religion',\n",
       " 333: 'online_crime,health_shaming',\n",
       " 334: 'offline_crime,pornography,body_shaming',\n",
       " 335: 'drugs,gambling',\n",
       " 336: 'offline_crime,pornography,prostitution,sexism'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_vaiables_id2topic_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_multilabel_onedim(y):\n",
    "    y_adjusted = []\n",
    "    for y_c in y:\n",
    "        y_test_curr = [0]*19\n",
    "        y_c = target_vaiables_id2topic_dict[y_c]\n",
    "        for tag in y_c.split(\",\"):\n",
    "            topic_index = topics_list.index(tag)\n",
    "            y_test_curr[topic_index] = 1\n",
    "        y_adjusted.append(y_test_curr)\n",
    "#         break\n",
    "    return y_adjusted\n",
    "\n",
    "def compute_metrics(labels, pred):\n",
    "#     labels = adjust_multilabel(labels)\n",
    "#     pred = adjust_multilabel(pred)\n",
    "    \n",
    "    labels = adjust_multilabel_onedim(labels)\n",
    "    pred = adjust_multilabel_onedim(pred)\n",
    "    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, pred, average='weighted', zero_division = 0)\n",
    "    acc = accuracy_score(labels, pred)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val = train_val[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngram_range (1, 2), max_features 10000\n",
      "[[0.12664284 0.87335716]\n",
      " [0.12603681 0.87396319]\n",
      " [0.15762659 0.84237341]\n",
      " [0.14245733 0.85754267]\n",
      " [0.12170813 0.87829187]\n",
      " [0.1240401  0.8759599 ]\n",
      " [0.13955384 0.86044616]\n",
      " [0.12614296 0.87385704]\n",
      " [0.12912911 0.87087089]\n",
      " [0.12425459 0.87574541]]\n",
      "{'accuracy': 0.027129337539432176, 'f1': 0.008116440516430698, 'precision': 0.004375708783148285, 'recall': 0.05593143888137122}\n"
     ]
    }
   ],
   "source": [
    "def check_tfidf_onedim(sw = None, ngram_range=(1, 3), max_features=150000, text_label = 'text'):\n",
    "    \n",
    "    print(\"ngram_range {}, max_features {}\".format(ngram_range, max_features))\n",
    "    \n",
    "    text_transformer = TfidfVectorizer(stop_words=sw, ngram_range=ngram_range, lowercase=True, max_features=max_features)\n",
    "    \n",
    "    X_train_text = text_transformer.fit_transform(train_val[text_label].tolist())\n",
    "    X_test_text = text_transformer.transform(df_test[text_label])\n",
    "    \n",
    "    logit = LogisticRegression(solver=\"liblinear\")#(multi_class='multinomial', solver='lbfgs',random_state=17, n_jobs=2)\n",
    "    \n",
    "   \n",
    "    logit.fit(X_train_text, train_val['class'])\n",
    "    test_preds = logit.predict(X_test_text)\n",
    "    \n",
    "    test_preds_proba = logit.predict_proba(X_test_text)\n",
    "    print(test_preds_proba[:10])\n",
    "    \n",
    "    metrics = compute_metrics(df_test['class'],test_preds)\n",
    "    \n",
    "    print(metrics)\n",
    "    \n",
    "#     return test_preds\n",
    " \n",
    "res = check_tfidf_onedim(russian_stopwords, (1,2), 10000, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "X, y = load_iris(return_X_y=True)\n",
    "clf = LogisticRegression(solver=\"liblinear\").fit(X, y)\n",
    "y[:10]\n",
    "# clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.78030305e-01, 1.21958900e-01, 1.07949250e-05],\n",
       "       [7.97058292e-01, 2.02911413e-01, 3.02949242e-05],\n",
       "       [8.51997665e-01, 1.47976480e-01, 2.58550858e-05],\n",
       "       [8.23406019e-01, 1.76536159e-01, 5.78217704e-05],\n",
       "       [8.96034973e-01, 1.03953836e-01, 1.11907339e-05],\n",
       "       [9.26234254e-01, 7.37527845e-02, 1.29612594e-05],\n",
       "       [8.94096848e-01, 1.05863935e-01, 3.92166195e-05],\n",
       "       [8.60034410e-01, 1.39946715e-01, 1.88751124e-05],\n",
       "       [8.01028643e-01, 1.98886755e-01, 8.46025595e-05],\n",
       "       [7.92662392e-01, 2.07312003e-01, 2.56051563e-05]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def adjust_multilabel(y):\n",
    "#     y_adjusted = []\n",
    "#     for y_c in y:\n",
    "#         y_test_curr = [0]*19\n",
    "# #         print(y_c)\n",
    "#         y_c = target_vaiables_id2topic_dict[np.argmax(y_c)]\n",
    "# #         print(y_c)\n",
    "#         for tag in y_c.split(\",\"):\n",
    "#             topic_index = topics_list.index(tag)\n",
    "#             y_test_curr[topic_index] = 1\n",
    "#         y_adjusted.append(y_test_curr)\n",
    "# #         break\n",
    "#     return y_adjusted\n",
    "\n",
    "# adjust_multilabel(test_list)\n",
    "\n",
    "\n",
    "# compute_metrics(test_list,res)\n",
    "# compute_metrics(df_test['class'].tolist(),res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_tfidf(sw = None, ngram_range=(1, 3), max_features=150000, text_label = 'text'):\n",
    "    \n",
    "#     print(\"ngram_range {}, max_features {}\".format(ngram_range, max_features))\n",
    "    \n",
    "#     text_transformer = TfidfVectorizer(stop_words=sw, ngram_range=ngram_range, lowercase=True, max_features=max_features)\n",
    "#     X_train_text = text_transformer.fit_transform(train_val[text_label].tolist())\n",
    "    \n",
    "# #     print(X_train_text)\n",
    "# #     raise Exception(\"STOPE\")\n",
    "    \n",
    "#     X_test_text = text_transformer.transform(df_test[text_label])\n",
    "\n",
    "# #     logit = LogisticRegression(C=5e1, solver='lbfgs', multi_class='multinomial', random_state=17, n_jobs=4)\n",
    "    \n",
    "#     logit = MultiOutputClassifier(estimator= LogisticRegression(random_state=17, n_jobs=-1)) \n",
    "\n",
    "# #     skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=17)\n",
    "\n",
    "# #     cv_results = cross_val_score(logit, X_train_text, trval_list, cv=skf, scoring='f1_micro')\n",
    "\n",
    "# #     print(cv_results, cv_results.mean())\n",
    "    \n",
    "#     logit.fit(X_train_text, trval_list)\n",
    "#     test_preds = logit.predict(X_test_text)\n",
    "#     metrics = compute_metrics(test_list,test_preds)\n",
    "    \n",
    "#     print(metrics)\n",
    "\n",
    "    \n",
    "# # check_tfidf()   \n",
    "# check_tfidf(russian_stopwords, (1,2), 10000, 'processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngram_range (1, 3), max_features 100000\n"
     ]
    }
   ],
   "source": [
    "for ngram in [(1,3),(1,4)]:\n",
    "    for feat in [100000, 300000]:\n",
    "        check_tfidf_onedim(russian_stopwords, ngram, feat, 'processed')    \n",
    "        print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_SVM(ngram_range=(1, 3), max_features=150000, kernel = 'linear'):\n",
    "    \n",
    "    print(\"ngram_range {}, max_features {}\".format(ngram_range, max_features))\n",
    "    \n",
    "    text_transformer = TfidfVectorizer(stop_words=russian_stopwords, ngram_range=ngram_range, lowercase=True, max_features=max_features)\n",
    "    X_train_text = text_transformer.fit_transform(train_val['processed'].tolist())\n",
    "    \n",
    "    X_test_text = text_transformer.transform(df_test['processed'])\n",
    "\n",
    "#     logit = LogisticRegression(C=5e1, solver='lbfgs', multi_class='multinomial', random_state=17, n_jobs=4)\n",
    "    logit = SVC(kernel = kernel)\n",
    "    print(\"fitting ...\")\n",
    "    logit.fit(X_train_text, train_val['inappropriate'])\n",
    "    test_preds = logit.predict(X_test_text)\n",
    "    print(classification_report(df_test['inappropriate'], test_preds))\n",
    "    \n",
    "    check_SVM\n",
    "    \n",
    "check_SVM()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
