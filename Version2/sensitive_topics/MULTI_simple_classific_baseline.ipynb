{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mutlti logreg sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10) (1000,)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, n_classes=3, random_state=1)\n",
    "# summarize the dataset\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.89149379, -0.39847585,  1.63856893,  0.01647165,  1.51892395,\n",
       "        -3.52651223,  1.80998823,  0.58810926, -0.02542177, -0.52835426],\n",
       "       [ 1.86913773, -0.56336215,  2.03411807,  0.38669445, -0.09584042,\n",
       "        -2.92724017,  0.73921674, -0.55633   , -0.27340013,  0.72129251],\n",
       "       [ 1.95259701, -2.83144572,  0.19055535, -0.66388697,  0.19159093,\n",
       "        -1.8591214 , -0.10150205, -0.60957741, -2.07750191, -1.75469982],\n",
       "       [-0.67042514, -0.69082031,  0.59354753, -0.06270367,  2.37357676,\n",
       "        -0.52106039,  0.42872513, -0.26851085,  0.49226161, -1.34383965],\n",
       "       [-1.39890137, -0.71522959, -0.6774507 ,  0.39153885, -0.45832391,\n",
       "         2.17898372, -1.88550244, -0.96686613, -0.42588787, -0.20782615],\n",
       "       [-2.94551044, -0.79851493, -1.92807818, -0.11749422,  3.75941261,\n",
       "         2.55924496, -0.71375699,  0.87323395,  0.26641973, -3.52801155],\n",
       "       [-0.99746413, -1.35338763, -1.50586396, -1.73258977,  3.66110299,\n",
       "         0.44739896,  1.27005199,  0.76439032,  0.10839262, -3.74038228],\n",
       "       [-0.26028138,  0.51739762,  1.78389329,  2.51998179,  1.46572279,\n",
       "        -1.50616812, -0.68426509,  0.64095725,  0.27620903,  0.3131776 ],\n",
       "       [ 1.00862774, -4.44379822, -0.23197007, -1.01409556, -0.10921532,\n",
       "        -0.17692105, -1.63553575, -2.32000882, -2.71351248, -2.35483141],\n",
       "       [ 2.83315115, -2.64365032,  3.93779191,  3.74756698,  4.70060001,\n",
       "        -7.08044923,  0.01118705,  1.61033554, -2.04795128, -2.74329857]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 2, 0, 2, 2, 2, 0, 0])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.681 (0.042)\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, n_classes=3, random_state=1)\n",
    "# define the multinomial logistic regression model\n",
    "model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "# define the model evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate the model and collect the scores\n",
    "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report the model performance\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "\n",
    "# import eli5\n",
    "\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_multilabel_classification(n_classes=3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3., 6., 1., ..., 1., 5., 0.],\n",
       "       [3., 5., 5., ..., 1., 1., 1.],\n",
       "       [3., 3., 5., ..., 0., 2., 1.],\n",
       "       ...,\n",
       "       [3., 7., 3., ..., 2., 4., 2.],\n",
       "       [7., 2., 1., ..., 1., 1., 1.],\n",
       "       [3., 5., 3., ..., 1., 2., 4.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0],\n",
       "       [0, 1, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "RST = 0\n",
    "df = pd.read_csv(\"./compare_manual_manuallVSsemiauto/train_manualVSsemiauto_rst_{}.csv\".format(RST))\n",
    "df_val = pd.read_csv(\"./compare_manual_manuallVSsemiauto/val_manual_only_rst_{}.csv\".format(RST))\n",
    "df_test = pd.read_csv(\"./compare_manual_manuallVSsemiauto/test_manual_only_rst_{}.csv\".format(RST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['offline_crime',\n",
       " 'online_crime',\n",
       " 'drugs',\n",
       " 'gambling',\n",
       " 'pornography',\n",
       " 'prostitution',\n",
       " 'slavery',\n",
       " 'suicide',\n",
       " 'terrorism',\n",
       " 'weapons',\n",
       " 'body_shaming',\n",
       " 'health_shaming',\n",
       " 'politics',\n",
       " 'racism',\n",
       " 'religion',\n",
       " 'sexual_minorities',\n",
       " 'sexism',\n",
       " 'social_injustice',\n",
       " 'none']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "necessary_columns = list(df.columns)[1:] \n",
    "topics_list = necessary_columns + ['none']\n",
    "topics_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(dataframe):\n",
    "    labels =[]\n",
    "    for i, el in dataframe.iterrows():\n",
    "        current_sample_labels = []\n",
    "        any_class = False\n",
    "        for clm in necessary_columns:\n",
    "            if el[clm] == 1:\n",
    "                any_class = True\n",
    "                current_sample_labels.append(clm)\n",
    "        if any_class == False:\n",
    "            current_sample_labels.append(\"none\")\n",
    "        current_sample_labels = ','.join(current_sample_labels)\n",
    "        labels.append(current_sample_labels)\n",
    "    return labels\n",
    "train_labels = get_labels(df)\n",
    "val_labels = get_labels(df_val)\n",
    "test_labels = get_labels(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['offline_crime', 'none', 'offline_crime', 'offline_crime', 'offline_crime']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'text':list(df['text']), 'labels':train_labels})\n",
    "df_val = pd.DataFrame({'text':list(df_val['text']), 'labels':val_labels})\n",
    "df_test = pd.DataFrame({'text':list(df_test['text']), 'labels':test_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = dict()\n",
    "mapping['none'] = 0\n",
    "\n",
    "for label in train_labels:\n",
    "    if label not in mapping:\n",
    "        mapping[label] = len(mapping)\n",
    "\n",
    "for label in test_labels:\n",
    "    if label not in mapping:\n",
    "        mapping[label] = len(mapping)\n",
    "        \n",
    "for label in val_labels:\n",
    "    if label not in mapping:\n",
    "        mapping[label] = len(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'] = df['labels'].apply(lambda x: mapping[x])\n",
    "df_test['class'] = df_test['labels'].apply(lambda x: mapping[x])\n",
    "df_val['class'] = df_val['labels'].apply(lambda x: mapping[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ман, можно же ведь и сабцы навернуть!А можно и...</td>\n",
       "      <td>offline_crime</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Чтобы не было на них постороннего давления... ...</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>С 12 лет на трое суток, а потом пять лет тюрьм...</td>\n",
       "      <td>offline_crime</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>там и смертная казнь есть за некоторые преступ...</td>\n",
       "      <td>offline_crime</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Есть убивство во благо . И каждый настоящий че...</td>\n",
       "      <td>offline_crime</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text         labels  class\n",
       "0  Ман, можно же ведь и сабцы навернуть!А можно и...  offline_crime      1\n",
       "1  Чтобы не было на них постороннего давления... ...           none      0\n",
       "2  С 12 лет на трое суток, а потом пять лет тюрьм...  offline_crime      1\n",
       "3  там и смертная казнь есть за некоторые преступ...  offline_crime      1\n",
       "4  Есть убивство во благо . И каждый настоящий че...  offline_crime      1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val = pd.concat([df,df_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ман, можно же ведь и сабцы навернуть!А можно и...</td>\n",
       "      <td>offline_crime</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Чтобы не было на них постороннего давления... ...</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>С 12 лет на трое суток, а потом пять лет тюрьм...</td>\n",
       "      <td>offline_crime</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>там и смертная казнь есть за некоторые преступ...</td>\n",
       "      <td>offline_crime</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Есть убивство во благо . И каждый настоящий че...</td>\n",
       "      <td>offline_crime</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text         labels  class\n",
       "0  Ман, можно же ведь и сабцы навернуть!А можно и...  offline_crime      1\n",
       "1  Чтобы не было на них постороннего давления... ...           none      0\n",
       "2  С 12 лет на трое суток, а потом пять лет тюрьм...  offline_crime      1\n",
       "3  там и смертная казнь есть за некоторые преступ...  offline_crime      1\n",
       "4  Есть убивство во благо . И каждый настоящий че...  offline_crime      1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Стреляют по ногам чтобы не убить а там артерия...</td>\n",
       "      <td>offline_crime</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Если тебе дали в морду, а ты пырнул ножом - до...</td>\n",
       "      <td>offline_crime</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Какие доказательства нужны, чтобы суд вынес об...</td>\n",
       "      <td>offline_crime</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>протокол составить на родителей. И выписать им...</td>\n",
       "      <td>offline_crime</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Правда ли что коллекторы могут по законы силой...</td>\n",
       "      <td>offline_crime</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text         labels  class\n",
       "0  Стреляют по ногам чтобы не убить а там артерия...  offline_crime      1\n",
       "1  Если тебе дали в морду, а ты пырнул ножом - до...  offline_crime      1\n",
       "2  Какие доказательства нужны, чтобы суд вынес об...  offline_crime      1\n",
       "3  протокол составить на родителей. И выписать им...  offline_crime      1\n",
       "4  Правда ли что коллекторы могут по законы силой...  offline_crime      1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_encoder = OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trval_list = np.array(train_val['class'].tolist())\n",
    "trval_list  = trval_list.reshape(-1, 1)\n",
    "trval_list = onehot_encoder.fit_transform(trval_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = np.array(df_test['class'].tolist())\n",
    "test_list  = test_list.reshape(-1, 1)\n",
    "test_list = onehot_encoder.fit_transform(test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-idf logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/kashnitsky/logistic-regression-tf-idf-baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\N.Babakov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'мама мыло'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "import re\n",
    "\n",
    "\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "from pymystem3 import Mystem\n",
    "from string import punctuation\n",
    "from tqdm import tqdm\n",
    "mystem = Mystem() \n",
    "\n",
    "def preprocess_text(text):\n",
    "    \n",
    "    text = re.sub(\"[^а-яА-Я]\",\" \",text)\n",
    "    text = re.sub(\" +\",\" \",text)\n",
    "    text = text.split()\n",
    "\n",
    "    tokens = [morph.parse(w)[0].normal_form for w in text]\n",
    "    tokens = [token for token in tokens if token not in russian_stopwords\\\n",
    "              and token != \" \" \\\n",
    "              and token.strip() not in punctuation]\n",
    "    \n",
    "    text = \" \".join(tokens)\n",
    "    \n",
    "    return text\n",
    "\n",
    "preprocess_text(\"мама23663 мыла /!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 34542/34542 [02:33<00:00, 224.34it/s]\n"
     ]
    }
   ],
   "source": [
    "processed = []\n",
    "for t in tqdm(train_val['text'].tolist()):\n",
    "    pr = preprocess_text(t)\n",
    "    processed.append(pr)\n",
    "    \n",
    "train_val['processed'] = processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1585/1585 [00:05<00:00, 310.61it/s]\n"
     ]
    }
   ],
   "source": [
    "processed = []\n",
    "for t in tqdm(df_test['text'].tolist()):\n",
    "    pr = preprocess_text(t)\n",
    "    processed.append(pr)\n",
    "df_test['processed'] = processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_vaiables_id2topic_dict = {val:key for key, val in mapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngram_range (1, 2), max_features 10000\n",
      "{'accuracy': 0.4769716088328076, 'f1': 0.5347113331515103, 'precision': 0.7770162379784865, 'recall': 0.4821831303563374}\n"
     ]
    }
   ],
   "source": [
    "def check_tfidf_onedim(sw = None, ngram_range=(1, 3), max_features=150000, text_label = 'text'):\n",
    "    \n",
    "    print(\"ngram_range {}, max_features {}\".format(ngram_range, max_features))\n",
    "    \n",
    "    text_transformer = TfidfVectorizer(stop_words=sw, ngram_range=ngram_range, lowercase=True, max_features=max_features)\n",
    "    \n",
    "    X_train_text = text_transformer.fit_transform(train_val[text_label].tolist())\n",
    "    X_test_text = text_transformer.transform(df_test[text_label])\n",
    "    \n",
    "    logit = LogisticRegression(multi_class='multinomial', solver='lbfgs',random_state=17, n_jobs=2)\n",
    "    \n",
    "#     cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "#     n_scores = cross_val_score(logit, X_train_text, train_val['class'], scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "#     print('Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "    \n",
    "    logit.fit(X_train_text, train_val['class'])\n",
    "    test_preds = logit.predict(X_test_text)\n",
    "    metrics = compute_metrics(df_test['class'],test_preds)\n",
    "    \n",
    "    print(metrics)\n",
    "    \n",
    "#     return test_preds\n",
    " \n",
    "res = check_tfidf_onedim(russian_stopwords, (1,2), 10000, 'processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def adjust_multilabel(y):\n",
    "#     y_adjusted = []\n",
    "#     for y_c in y:\n",
    "#         y_test_curr = [0]*19\n",
    "# #         print(y_c)\n",
    "#         y_c = target_vaiables_id2topic_dict[np.argmax(y_c)]\n",
    "# #         print(y_c)\n",
    "#         for tag in y_c.split(\",\"):\n",
    "#             topic_index = topics_list.index(tag)\n",
    "#             y_test_curr[topic_index] = 1\n",
    "#         y_adjusted.append(y_test_curr)\n",
    "# #         break\n",
    "#     return y_adjusted\n",
    "\n",
    "# adjust_multilabel(test_list)\n",
    "\n",
    "def adjust_multilabel_onedim(y):\n",
    "    y_adjusted = []\n",
    "    for y_c in y:\n",
    "        y_test_curr = [0]*19\n",
    "        y_c = target_vaiables_id2topic_dict[y_c]\n",
    "        for tag in y_c.split(\",\"):\n",
    "            topic_index = topics_list.index(tag)\n",
    "            y_test_curr[topic_index] = 1\n",
    "        y_adjusted.append(y_test_curr)\n",
    "#         break\n",
    "    return y_adjusted\n",
    "\n",
    "def compute_metrics(labels, pred):\n",
    "#     labels = adjust_multilabel(labels)\n",
    "#     pred = adjust_multilabel(pred)\n",
    "    \n",
    "    labels = adjust_multilabel_onedim(labels)\n",
    "    pred = adjust_multilabel_onedim(pred)\n",
    "    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, pred, average='weighted', zero_division = 0)\n",
    "    acc = accuracy_score(labels, pred)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "# compute_metrics(test_list,res)\n",
    "# compute_metrics(df_test['class'].tolist(),res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_tfidf(sw = None, ngram_range=(1, 3), max_features=150000, text_label = 'text'):\n",
    "    \n",
    "#     print(\"ngram_range {}, max_features {}\".format(ngram_range, max_features))\n",
    "    \n",
    "#     text_transformer = TfidfVectorizer(stop_words=sw, ngram_range=ngram_range, lowercase=True, max_features=max_features)\n",
    "#     X_train_text = text_transformer.fit_transform(train_val[text_label].tolist())\n",
    "    \n",
    "# #     print(X_train_text)\n",
    "# #     raise Exception(\"STOPE\")\n",
    "    \n",
    "#     X_test_text = text_transformer.transform(df_test[text_label])\n",
    "\n",
    "# #     logit = LogisticRegression(C=5e1, solver='lbfgs', multi_class='multinomial', random_state=17, n_jobs=4)\n",
    "    \n",
    "#     logit = MultiOutputClassifier(estimator= LogisticRegression(random_state=17, n_jobs=-1)) \n",
    "\n",
    "# #     skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=17)\n",
    "\n",
    "# #     cv_results = cross_val_score(logit, X_train_text, trval_list, cv=skf, scoring='f1_micro')\n",
    "\n",
    "# #     print(cv_results, cv_results.mean())\n",
    "    \n",
    "#     logit.fit(X_train_text, trval_list)\n",
    "#     test_preds = logit.predict(X_test_text)\n",
    "#     metrics = compute_metrics(test_list,test_preds)\n",
    "    \n",
    "#     print(metrics)\n",
    "\n",
    "    \n",
    "# # check_tfidf()   \n",
    "# check_tfidf(russian_stopwords, (1,2), 10000, 'processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngram_range (1, 3), max_features 100000\n"
     ]
    }
   ],
   "source": [
    "for ngram in [(1,3),(1,4)]:\n",
    "    for feat in [100000, 300000]:\n",
    "        check_tfidf_onedim(russian_stopwords, ngram, feat, 'processed')    \n",
    "        print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_SVM(ngram_range=(1, 3), max_features=150000, kernel = 'linear'):\n",
    "    \n",
    "    print(\"ngram_range {}, max_features {}\".format(ngram_range, max_features))\n",
    "    \n",
    "    text_transformer = TfidfVectorizer(stop_words=russian_stopwords, ngram_range=ngram_range, lowercase=True, max_features=max_features)\n",
    "    X_train_text = text_transformer.fit_transform(train_val['processed'].tolist())\n",
    "    \n",
    "    X_test_text = text_transformer.transform(df_test['processed'])\n",
    "\n",
    "#     logit = LogisticRegression(C=5e1, solver='lbfgs', multi_class='multinomial', random_state=17, n_jobs=4)\n",
    "    logit = SVC(kernel = kernel)\n",
    "    print(\"fitting ...\")\n",
    "    logit.fit(X_train_text, train_val['inappropriate'])\n",
    "    test_preds = logit.predict(X_test_text)\n",
    "    print(classification_report(df_test['inappropriate'], test_preds))\n",
    "    \n",
    "    check_SVM\n",
    "    \n",
    "check_SVM()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
