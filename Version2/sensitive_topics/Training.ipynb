{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "\n",
    "from transformers.trainer_callback import EarlyStoppingCallback\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./compare_manual_manuallVSsemiauto/train_manualVSsemiauto_rst_2.csv')\n",
    "df_val = pd.read_csv('./compare_manual_manuallVSsemiauto/val_manual_only_rst_2.csv')\n",
    "df_test = pd.read_csv('./compare_manual_manuallVSsemiauto/test_manual_only_rst_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>offline_crime</th>\n",
       "      <th>online_crime</th>\n",
       "      <th>drugs</th>\n",
       "      <th>gambling</th>\n",
       "      <th>pornography</th>\n",
       "      <th>prostitution</th>\n",
       "      <th>slavery</th>\n",
       "      <th>suicide</th>\n",
       "      <th>terrorism</th>\n",
       "      <th>weapons</th>\n",
       "      <th>body_shaming</th>\n",
       "      <th>health_shaming</th>\n",
       "      <th>politics</th>\n",
       "      <th>racism</th>\n",
       "      <th>religion</th>\n",
       "      <th>sexual_minorities</th>\n",
       "      <th>sexism</th>\n",
       "      <th>social_injustice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>есть такой лайфхак у футбольных фанатов перед ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Еще один йоба-знаток, у которого грабеж==разбой</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Зря тут этот пост. Теперь дом спиздят</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Не знаю статью, но один мужчина заступился физ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>idДвачую адвоката адеквата.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  offline_crime  \\\n",
       "0  есть такой лайфхак у футбольных фанатов перед ...            1.0   \n",
       "1    Еще один йоба-знаток, у которого грабеж==разбой            1.0   \n",
       "2              Зря тут этот пост. Теперь дом спиздят            1.0   \n",
       "3  Не знаю статью, но один мужчина заступился физ...            1.0   \n",
       "4                        idДвачую адвоката адеквата.            1.0   \n",
       "\n",
       "   online_crime  drugs  gambling  pornography  prostitution  slavery  suicide  \\\n",
       "0           0.0    0.0       0.0          0.0           0.0      0.0      0.0   \n",
       "1           0.0    0.0       0.0          0.0           0.0      0.0      0.0   \n",
       "2           0.0    0.0       0.0          0.0           0.0      0.0      0.0   \n",
       "3           0.0    0.0       0.0          0.0           0.0      0.0      0.0   \n",
       "4           0.0    0.0       0.0          0.0           0.0      0.0      0.0   \n",
       "\n",
       "   terrorism  weapons  body_shaming  health_shaming  politics  racism  \\\n",
       "0        0.0      0.0           0.0             0.0       0.0     0.0   \n",
       "1        0.0      0.0           0.0             0.0       0.0     0.0   \n",
       "2        0.0      0.0           0.0             0.0       0.0     0.0   \n",
       "3        0.0      0.0           0.0             0.0       0.0     0.0   \n",
       "4        0.0      0.0           0.0             0.0       0.0     0.0   \n",
       "\n",
       "   religion  sexual_minorities  sexism  social_injustice  \n",
       "0       0.0                0.0    0.00              0.00  \n",
       "1       0.0                0.0    0.00              0.17  \n",
       "2       0.0                0.0    0.00              0.00  \n",
       "3       0.0                0.0    0.18              0.00  \n",
       "4       0.0                0.0    0.00              0.00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "necessary_columns = list(df.columns)[1:] \n",
    "# necessary_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(dataframe):\n",
    "    labels =[]\n",
    "    for i, el in dataframe.iterrows():\n",
    "        current_sample_labels = []\n",
    "        any_class = False\n",
    "        for clm in necessary_columns:\n",
    "            if el[clm] == 1:\n",
    "                any_class = True\n",
    "                current_sample_labels.append(clm)\n",
    "        if any_class == False:\n",
    "            current_sample_labels.append(\"none\")\n",
    "        current_sample_labels = ','.join(current_sample_labels)\n",
    "        labels.append(current_sample_labels)\n",
    "    return labels\n",
    "train_labels = get_labels(df)\n",
    "val_labels = get_labels(df_val)\n",
    "test_labels = get_labels(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_adjusted = pd.DataFrame({'text':list(df['text']), 'labels':train_labels})\n",
    "df_val_adjusted = pd.DataFrame({'text':list(df_val['text']), 'labels':val_labels})\n",
    "df_test_adjusted = pd.DataFrame({'text':list(df_test['text']), 'labels':test_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = dict()\n",
    "mapping['none'] = 0\n",
    "\n",
    "for label in train_labels:\n",
    "    if label not in mapping:\n",
    "        mapping[label] = len(mapping)\n",
    "\n",
    "for label in test_labels:\n",
    "    if label not in mapping:\n",
    "        mapping[label] = len(mapping)\n",
    "        \n",
    "for label in val_labels:\n",
    "    if label not in mapping:\n",
    "        mapping[label] = len(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "337"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_adjusted['class'] = df_train_adjusted['labels'].apply(lambda x: mapping[x])\n",
    "df_test_adjusted['class'] = df_test_adjusted['labels'].apply(lambda x: mapping[x])\n",
    "df_val_adjusted['class'] = df_val_adjusted['labels'].apply(lambda x: mapping[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_val = df_val_adjusted['labels'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train_adjusted['text'].tolist()\n",
    "y_train = df_train_adjusted['class'].tolist()\n",
    "x_test = df_test_adjusted['text'].tolist()\n",
    "y_test = df_test_adjusted['class'].tolist()\n",
    "x_val = df_val_adjusted['text'].tolist()\n",
    "y_val = df_val_adjusted['class'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnsafeData(Dataset):\n",
    "\n",
    "    def __init__(self, texts, targets, tokenizer, max_len):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.texts = texts\n",
    "        self.targets = targets        \n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.texts)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = self.texts[index]\n",
    "\n",
    "        enc_dict = self.tokenizer(x, truncation=True, max_length=self.max_len, padding='max_length')\n",
    "      \n",
    "        item = {key: torch.tensor(val).long() for key, val in enc_dict.items()}\n",
    "        item['labels'] = torch.tensor(self.targets[index]).long()\n",
    "\n",
    "        return item "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'DeepPavlov/rubert-base-cased-conversational'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased-conversational and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels = len(mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = UnsafeData(x_train, y_train, tokenizer, max_len = 60)\n",
    "test_dataset = UnsafeData(x_test, y_test, tokenizer, max_len = 60)\n",
    "val_dataset = UnsafeData(x_val, y_val, tokenizer, max_len = 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33100, 1585, 1442)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(test_dataset), len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_dataset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_list = necessary_columns + ['none']\n",
    "# topics_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_vaiables_id2topic_dict = {val:key for key, val in mapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# with open(\"id2topic.json\",\"w\") as f:\n",
    "#     json.dump(target_vaiables_id2topic_dict, f, indent = 2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "337"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_vaiables_id2topic_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_multilabel(y, is_pred = False):\n",
    "    y_adjusted = []\n",
    "    for y_c in y:\n",
    "        y_test_curr = [0]*19\n",
    "        if is_pred == True:\n",
    "            y_c = target_vaiables_id2topic_dict[np.argmax(y_c)]\n",
    "        else:\n",
    "            y_c = target_vaiables_id2topic_dict[y_c]\n",
    "        for tag in y_c.split(\",\"):\n",
    "            topic_index = topics_list.index(tag)\n",
    "            y_test_curr[topic_index] = 1\n",
    "        y_adjusted.append(y_test_curr)\n",
    "    return y_adjusted\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y = load_breast_cancer(return_X_y=True)\n",
    "# clf = LogisticRegression(solver=\"liblinear\", random_state=0).fit(X, y)\n",
    "# roc_auc_score(y, clf.predict_proba(X)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    labels = adjust_multilabel(labels, is_pred = False)\n",
    "    preds = pred.predictions\n",
    "    \n",
    "    preds = adjust_multilabel(preds, is_pred = True)\n",
    "        \n",
    "    rauc = roc_auc_score(labels,preds)\n",
    "    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted', zero_division = 0)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'rauc':rauc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers.file_utils import cached_property\n",
    "from typing import Tuple\n",
    "\n",
    "device = torch.device('cuda:1')\n",
    "\n",
    "class TrAr(TrainingArguments):\n",
    "    @cached_property\n",
    "    def _setup_devices(self) -> Tuple[\"torch.device\", int]:\n",
    "        return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(device)\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrAr(\n",
    "    output_dir='/multi_model/publ',\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    logging_steps = 600,\n",
    "    evaluation_strategy = 'steps',\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    save_steps = 500,\n",
    "    eval_steps = 500, #500,\n",
    "    metric_for_best_model  = 'f1',\n",
    "    greater_is_better = True,\n",
    "    load_best_model_at_end = True, report_to = 'none' \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "def cleanup():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.add_callback(EarlyStoppingCallback(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 33100\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10345\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8000' max='10345' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 8000/10345 15:44 < 04:36, 8.47 it/s, Epoch 3/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Rauc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.630738</td>\n",
       "      <td>0.478502</td>\n",
       "      <td>0.486983</td>\n",
       "      <td>0.724036</td>\n",
       "      <td>0.477069</td>\n",
       "      <td>0.717940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.040000</td>\n",
       "      <td>2.387581</td>\n",
       "      <td>0.514563</td>\n",
       "      <td>0.608976</td>\n",
       "      <td>0.771198</td>\n",
       "      <td>0.551924</td>\n",
       "      <td>0.782451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>2.178283</td>\n",
       "      <td>0.538141</td>\n",
       "      <td>0.621697</td>\n",
       "      <td>0.772885</td>\n",
       "      <td>0.568793</td>\n",
       "      <td>0.766451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.978200</td>\n",
       "      <td>1.961584</td>\n",
       "      <td>0.563800</td>\n",
       "      <td>0.681448</td>\n",
       "      <td>0.776126</td>\n",
       "      <td>0.616236</td>\n",
       "      <td>0.788400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.804900</td>\n",
       "      <td>1.902267</td>\n",
       "      <td>0.573509</td>\n",
       "      <td>0.677517</td>\n",
       "      <td>0.781782</td>\n",
       "      <td>0.617818</td>\n",
       "      <td>0.784402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.665100</td>\n",
       "      <td>1.934716</td>\n",
       "      <td>0.576283</td>\n",
       "      <td>0.687686</td>\n",
       "      <td>0.780350</td>\n",
       "      <td>0.631523</td>\n",
       "      <td>0.791105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.665100</td>\n",
       "      <td>1.923180</td>\n",
       "      <td>0.578363</td>\n",
       "      <td>0.684015</td>\n",
       "      <td>0.786313</td>\n",
       "      <td>0.625198</td>\n",
       "      <td>0.806356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.655600</td>\n",
       "      <td>1.742534</td>\n",
       "      <td>0.602635</td>\n",
       "      <td>0.701976</td>\n",
       "      <td>0.801302</td>\n",
       "      <td>0.647865</td>\n",
       "      <td>0.795234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.618000</td>\n",
       "      <td>1.873510</td>\n",
       "      <td>0.594313</td>\n",
       "      <td>0.718118</td>\n",
       "      <td>0.795319</td>\n",
       "      <td>0.665261</td>\n",
       "      <td>0.817082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.416600</td>\n",
       "      <td>1.836406</td>\n",
       "      <td>0.609570</td>\n",
       "      <td>0.716671</td>\n",
       "      <td>0.786064</td>\n",
       "      <td>0.672114</td>\n",
       "      <td>0.795633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.398300</td>\n",
       "      <td>1.912703</td>\n",
       "      <td>0.608877</td>\n",
       "      <td>0.725630</td>\n",
       "      <td>0.795185</td>\n",
       "      <td>0.677912</td>\n",
       "      <td>0.810911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.404900</td>\n",
       "      <td>1.926145</td>\n",
       "      <td>0.597087</td>\n",
       "      <td>0.709198</td>\n",
       "      <td>0.785152</td>\n",
       "      <td>0.659989</td>\n",
       "      <td>0.805687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.404900</td>\n",
       "      <td>2.000520</td>\n",
       "      <td>0.613037</td>\n",
       "      <td>0.729442</td>\n",
       "      <td>0.779143</td>\n",
       "      <td>0.693200</td>\n",
       "      <td>0.818765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.293400</td>\n",
       "      <td>2.027102</td>\n",
       "      <td>0.615118</td>\n",
       "      <td>0.734860</td>\n",
       "      <td>0.782242</td>\n",
       "      <td>0.700580</td>\n",
       "      <td>0.814929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.262600</td>\n",
       "      <td>2.112011</td>\n",
       "      <td>0.617892</td>\n",
       "      <td>0.728586</td>\n",
       "      <td>0.787867</td>\n",
       "      <td>0.685293</td>\n",
       "      <td>0.811571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.250700</td>\n",
       "      <td>2.095840</td>\n",
       "      <td>0.616505</td>\n",
       "      <td>0.727158</td>\n",
       "      <td>0.782022</td>\n",
       "      <td>0.687928</td>\n",
       "      <td>0.817406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1442\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /multi_model/publ/checkpoint-500\n",
      "Configuration saved in /multi_model/publ/checkpoint-500/config.json\n",
      "Model weights saved in /multi_model/publ/checkpoint-500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1442\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /multi_model/publ/checkpoint-1000\n",
      "Configuration saved in /multi_model/publ/checkpoint-1000/config.json\n",
      "Model weights saved in /multi_model/publ/checkpoint-1000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1442\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /multi_model/publ/checkpoint-1500\n",
      "Configuration saved in /multi_model/publ/checkpoint-1500/config.json\n",
      "Model weights saved in /multi_model/publ/checkpoint-1500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1442\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /multi_model/publ/checkpoint-2000\n",
      "Configuration saved in /multi_model/publ/checkpoint-2000/config.json\n",
      "Model weights saved in /multi_model/publ/checkpoint-2000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1442\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /multi_model/publ/checkpoint-2500\n",
      "Configuration saved in /multi_model/publ/checkpoint-2500/config.json\n",
      "Model weights saved in /multi_model/publ/checkpoint-2500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1442\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /multi_model/publ/checkpoint-3000\n",
      "Configuration saved in /multi_model/publ/checkpoint-3000/config.json\n",
      "Model weights saved in /multi_model/publ/checkpoint-3000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1442\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /multi_model/publ/checkpoint-3500\n",
      "Configuration saved in /multi_model/publ/checkpoint-3500/config.json\n",
      "Model weights saved in /multi_model/publ/checkpoint-3500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1442\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /multi_model/publ/checkpoint-4000\n",
      "Configuration saved in /multi_model/publ/checkpoint-4000/config.json\n",
      "Model weights saved in /multi_model/publ/checkpoint-4000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1442\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /multi_model/publ/checkpoint-4500\n",
      "Configuration saved in /multi_model/publ/checkpoint-4500/config.json\n",
      "Model weights saved in /multi_model/publ/checkpoint-4500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1442\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /multi_model/publ/checkpoint-5000\n",
      "Configuration saved in /multi_model/publ/checkpoint-5000/config.json\n",
      "Model weights saved in /multi_model/publ/checkpoint-5000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1442\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /multi_model/publ/checkpoint-5500\n",
      "Configuration saved in /multi_model/publ/checkpoint-5500/config.json\n",
      "Model weights saved in /multi_model/publ/checkpoint-5500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1442\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /multi_model/publ/checkpoint-6000\n",
      "Configuration saved in /multi_model/publ/checkpoint-6000/config.json\n",
      "Model weights saved in /multi_model/publ/checkpoint-6000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1442\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /multi_model/publ/checkpoint-6500\n",
      "Configuration saved in /multi_model/publ/checkpoint-6500/config.json\n",
      "Model weights saved in /multi_model/publ/checkpoint-6500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1442\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /multi_model/publ/checkpoint-7000\n",
      "Configuration saved in /multi_model/publ/checkpoint-7000/config.json\n",
      "Model weights saved in /multi_model/publ/checkpoint-7000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1442\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /multi_model/publ/checkpoint-7500\n",
      "Configuration saved in /multi_model/publ/checkpoint-7500/config.json\n",
      "Model weights saved in /multi_model/publ/checkpoint-7500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1442\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /multi_model/publ/checkpoint-8000\n",
      "Configuration saved in /multi_model/publ/checkpoint-8000/config.json\n",
      "Model weights saved in /multi_model/publ/checkpoint-8000/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /multi_model/publ/checkpoint-7000 (score: 0.7348602994422789).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=8000, training_loss=0.7502470574378968, metrics={'train_runtime': 944.2284, 'train_samples_per_second': 175.275, 'train_steps_per_second': 10.956, 'total_flos': 3958165616781600.0, 'train_loss': 0.7502470574378968, 'epoch': 3.87})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1585\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.443035364151001,\n",
       " 'eval_accuracy': 0.5709779179810726,\n",
       " 'eval_f1': 0.6998859950532954,\n",
       " 'eval_precision': 0.7702140126538036,\n",
       " 'eval_recall': 0.651976374375284,\n",
       " 'eval_rauc': 0.8050120193381921,\n",
       " 'eval_runtime': 2.9449,\n",
       " 'eval_samples_per_second': 538.214,\n",
       " 'eval_steps_per_second': 33.957,\n",
       " 'epoch': 3.87}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "rst2 = {'eval_loss': 2.443035364151001,\n",
    " 'eval_accuracy': 0.5709779179810726,\n",
    " 'eval_f1': 0.6998859950532954,\n",
    " 'eval_precision': 0.7702140126538036,\n",
    " 'eval_recall': 0.651976374375284,\n",
    " 'eval_rauc': 0.8050120193381921,\n",
    " 'eval_runtime': 2.9449,\n",
    " 'eval_samples_per_second': 538.214,\n",
    " 'eval_steps_per_second': 33.957,\n",
    " 'epoch': 3.87}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rst1 = {'eval_loss': 2.356205701828003,\n",
    " 'eval_accuracy': 0.5754895767530006,\n",
    " 'eval_f1': 0.7109142859770795,\n",
    " 'eval_precision': 0.7573820406086228,\n",
    " 'eval_recall': 0.6744186046511628,\n",
    " 'eval_rauc': 0.8187230883371196,\n",
    " 'eval_runtime': 3.0342,\n",
    " 'eval_samples_per_second': 521.714,\n",
    " 'eval_steps_per_second': 32.628,\n",
    " 'epoch': 4.83}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rst0 = {'eval_loss': 2.919194221496582,\n",
    " 'eval_accuracy': 0.6082018927444794,\n",
    " 'eval_f1': 0.7347078777111259,\n",
    " 'eval_precision': 0.7787538848299613,\n",
    " 'eval_recall': 0.7023004059539919,\n",
    " 'eval_rauc': 0.8316562762180016,\n",
    " 'eval_runtime': 3.0124,\n",
    " 'eval_samples_per_second': 526.152,\n",
    " 'eval_steps_per_second': 33.196,\n",
    " 'epoch': 9.18}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_list = [rst0, rst1, rst2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "collected_data = []\n",
    "for r in res_list:\n",
    "    collected_data.append([r['eval_precision'],r['eval_recall'],r['eval_f1'],r['eval_rauc']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76878331, 0.67623179, 0.71516939, 0.81846379])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(collected_data, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00878347, 0.02058467, 0.01453089, 0.01087902])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(collected_data, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('multi-class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка на val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "source": [
    "pred = trainer.predict(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = pred.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31130, 1481, 692, 692)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df),len(df_test), len(df_val), len(adjust_multilabel(y_val, is_pred = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    offline_crime       0.64      0.54      0.58        52\n",
      "     online_crime       0.46      0.43      0.44        14\n",
      "            drugs       0.88      0.88      0.88        41\n",
      "         gambling       0.50      0.50      0.50         2\n",
      "      pornography       0.77      0.68      0.72        87\n",
      "     prostitution       0.87      0.80      0.84        41\n",
      "          slavery       0.72      0.87      0.79        15\n",
      "          suicide       0.50      0.67      0.57         3\n",
      "        terrorism       0.50      0.39      0.44        18\n",
      "          weapons       0.90      0.94      0.92        65\n",
      "     body_shaming       0.86      0.67      0.75        48\n",
      "   health_shaming       0.86      0.65      0.74        49\n",
      "         politics       0.73      0.56      0.63       109\n",
      "           racism       0.82      0.59      0.69        86\n",
      "         religion       0.90      0.80      0.84        44\n",
      "sexual_minorities       0.69      0.55      0.61        40\n",
      "           sexism       0.63      0.75      0.68        56\n",
      " social_injustice       0.57      0.37      0.45        81\n",
      "             none       0.67      0.69      0.68       126\n",
      "\n",
      "        micro avg       0.74      0.65      0.69       977\n",
      "        macro avg       0.71      0.65      0.67       977\n",
      "     weighted avg       0.74      0.65      0.69       977\n",
      "      samples avg       0.76      0.70      0.71       977\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(adjust_multilabel(y_val, is_pred = False), adjust_multilabel(pr, is_pred = True),\n",
    "                           target_names=topics_list, zero_division = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка на test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1585\n",
      "  Batch size = 16\n"
     ]
    }
   ],
   "source": [
    "pred2 = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr2 = pred2.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    offline_crime       0.69      0.60      0.64       124\n",
      "     online_crime       0.88      0.50      0.64        42\n",
      "            drugs       0.87      0.80      0.84        86\n",
      "         gambling       0.67      0.67      0.67         9\n",
      "      pornography       0.79      0.67      0.72       180\n",
      "     prostitution       0.77      0.82      0.80        88\n",
      "          slavery       0.81      0.85      0.83        34\n",
      "          suicide       0.44      0.44      0.44         9\n",
      "        terrorism       0.67      0.66      0.67        44\n",
      "          weapons       0.92      0.90      0.91       233\n",
      "     body_shaming       0.84      0.78      0.81       107\n",
      "   health_shaming       0.83      0.74      0.78       104\n",
      "         politics       0.76      0.60      0.67       222\n",
      "           racism       0.85      0.65      0.73       177\n",
      "         religion       0.93      0.67      0.78        95\n",
      "sexual_minorities       0.78      0.54      0.63        84\n",
      "           sexism       0.60      0.73      0.66       110\n",
      " social_injustice       0.58      0.56      0.57       147\n",
      "             none       0.74      0.76      0.75       322\n",
      "\n",
      "        micro avg       0.77      0.70      0.74      2217\n",
      "        macro avg       0.76      0.68      0.71      2217\n",
      "     weighted avg       0.78      0.70      0.73      2217\n",
      "      samples avg       0.79      0.75      0.75      2217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(adjust_multilabel(y_test, is_pred = False), adjust_multilabel(pr2, is_pred = True),\n",
    "                           target_names=topics_list, zero_division = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git', '.gitattributes']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "path = \"../../../../../russian-sensitive-topics\"\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../../../../../russian-sensitive-topics/tokenizer_config.json',\n",
       " '../../../../../russian-sensitive-topics/special_tokens_map.json',\n",
       " '../../../../../russian-sensitive-topics/vocab.txt',\n",
       " '../../../../../russian-sensitive-topics/added_tokens.json')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForSequenceClassification: ['bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tf_model = TFBertForSequenceClassification.from_pretrained(path, from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model.save_pretrained(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
